{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tour_code</th>\n",
       "      <th>tour_title</th>\n",
       "      <th>nights</th>\n",
       "      <th>days</th>\n",
       "      <th>day</th>\n",
       "      <th>location</th>\n",
       "      <th>activity</th>\n",
       "      <th>Typical visit time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4N5DKNEBC</td>\n",
       "      <td>04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>KANDY</td>\n",
       "      <td>PINNAWELA Elephant Orphanage</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4N5DKNEBC</td>\n",
       "      <td>04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>KANDY</td>\n",
       "      <td>Cultural dance show</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4N5DKNEBC</td>\n",
       "      <td>04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NUWARA ELIYA</td>\n",
       "      <td>KANDY Temple</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4N5DKNEBC</td>\n",
       "      <td>04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NUWARA ELIYA</td>\n",
       "      <td>Peradeniya Botanical Gardens</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4N5DKNEBC</td>\n",
       "      <td>04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NUWARA ELIYA</td>\n",
       "      <td>Gem Museum</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tour_code                                         tour_title  nights  days  \\\n",
       "0  4N5DKNEBC  04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...       4     5   \n",
       "1  4N5DKNEBC  04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...       4     5   \n",
       "2  4N5DKNEBC  04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...       4     5   \n",
       "3  4N5DKNEBC  04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...       4     5   \n",
       "4  4N5DKNEBC  04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...       4     5   \n",
       "\n",
       "   day      location                      activity Typical visit time  \n",
       "0    1         KANDY  PINNAWELA Elephant Orphanage            Morning  \n",
       "1    1         KANDY          Cultural dance show             Evening  \n",
       "2    2  NUWARA ELIYA                 KANDY Temple             Morning  \n",
       "3    2  NUWARA ELIYA  Peradeniya Botanical Gardens            Morning  \n",
       "4    2  NUWARA ELIYA                    Gem Museum            Morning  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = [\"kandy\",\"bentota\",\"nuwara eliya\"]\n",
    "duration = 4\n",
    "\n",
    "import pandas as pd\n",
    "itinerary = pd.read_csv(\"iternary 1(in).csv\", encoding='ISO-8859-1')\n",
    "itinerary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day counts & locations for the best matched tour :'04 Nights_05 Days_KANDYPINNAWELA NUWARA ELIYACOLOMBO':\n",
      "{'colombo': 2, 'kandy': 2, 'nuwara eliya': 1}\n",
      "Final List with days\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('kandy', 1), ('nuwara eliya', 2), ('bentota', 1)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def calculate_location_percentage_by_tour(itinerary_file, locations, duration):\n",
    "    itinerary = pd.read_csv(itinerary_file, encoding='ISO-8859-1')\n",
    "    itinerary['location'] = itinerary['location'].str.lower()\n",
    "    locations = [loc.lower() for loc in locations]\n",
    "    filtered_itinerary = itinerary[itinerary['days'] == duration]\n",
    "    \n",
    "    tour_location_percentages = {}\n",
    "    \n",
    "    for tour_title, tour_data in itinerary.groupby('tour_title'):\n",
    "        unique_tour_locations = tour_data['location'].unique().tolist()\n",
    "        \n",
    "        matching_locations = [loc for loc in locations if loc in unique_tour_locations]\n",
    "        if len(unique_tour_locations) > len(locations):\n",
    "          percentage = (len(matching_locations) / len(unique_tour_locations)) * 100\n",
    "        else:\n",
    "          percentage = (len(locations) / len(unique_tour_locations)) * 100\n",
    "        \n",
    "        tour_location_percentages[tour_title] = {\n",
    "            'percentage': percentage,\n",
    "            'matched_locations': matching_locations\n",
    "        }\n",
    "    \n",
    "    return tour_location_percentages\n",
    "\n",
    "def find_best_tour(results):\n",
    "    best_tour = None\n",
    "    min_difference = 100\n",
    "\n",
    "    for tour, data in results.items():\n",
    "      difference = abs(data['percentage'] - 100)\n",
    "      if difference == 0:\n",
    "        return tour\n",
    "      if difference < min_difference:\n",
    "        min_difference = difference\n",
    "        best_tour = tour\n",
    "      elif difference == min_difference and data['percentage'] > (results.get(best_tour, {})).get('percentage',0):\n",
    "        best_tour = tour\n",
    "    return best_tour\n",
    "\n",
    "def calculate_day_counts_by_location(itinerary_file, locations, tour_title):\n",
    "    itinerary = pd.read_csv(itinerary_file, encoding='ISO-8859-1')\n",
    "    \n",
    "    itinerary['location'] = itinerary['location'].str.lower()\n",
    "\n",
    "    filtered_itinerary = itinerary[itinerary['tour_title'] == tour_title]\n",
    "    \n",
    "    unique_days = filtered_itinerary.drop_duplicates(['location','day'])\n",
    "\n",
    "    location_day_count = unique_days.groupby(\"location\")[\"day\"].count()\n",
    "\n",
    "    return location_day_count.to_dict()\n",
    "\n",
    "def find_best_tour_with_days(itinerary_file, locations, duration):\n",
    "    result = calculate_location_percentage_by_tour(itinerary_file, locations, duration)\n",
    "    best_match = find_best_tour(result)\n",
    "    day_counts = calculate_day_counts_by_location(itinerary_file, locations, best_match)\n",
    "    \n",
    "    print(f\"Day counts & locations for the best matched tour :'{best_match}':\")\n",
    "    print(day_counts)\n",
    "    \n",
    "    # Initialize location days with 0\n",
    "    location_days = {loc.lower(): 0 for loc in locations}\n",
    "    \n",
    "    current_duration = 0\n",
    "    selected_locations = []\n",
    "\n",
    "    sorted_locations = sorted(day_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # First pass: allocate full days to matching locations\n",
    "    for location, days in sorted_locations:\n",
    "        if location in location_days:\n",
    "            # Allocate full days while not exceeding total duration\n",
    "            allocatable_days = min(days, duration - current_duration)\n",
    "            location_days[location] = allocatable_days\n",
    "            current_duration += allocatable_days\n",
    "            selected_locations.append((location, allocatable_days))\n",
    "            \n",
    "            # Break if we've reached the exact duration\n",
    "            if current_duration == duration:\n",
    "                break\n",
    "    \n",
    "    selected_location_names = [loc[0] for loc in selected_locations]\n",
    "    missing_locations = [loc for loc in locations if loc not in selected_location_names]\n",
    "    i=0\n",
    "    while (current_duration != duration) or len(missing_locations) != 0:\n",
    "\n",
    "      selected_cities = [city for city, _ in selected_locations]\n",
    "      missing_locations = [city for city in locations if city not in selected_cities]\n",
    "      if current_duration < duration:\n",
    "        lowest_location = min(selected_locations, key=lambda x: x[1])\n",
    "        index = selected_locations.index(lowest_location)\n",
    "        selected_locations[index] = (lowest_location[0], lowest_location[1] + 1)\n",
    "        current_duration += 1\n",
    "      elif current_duration > duration:\n",
    "        lowest_location = max(selected_locations, key=lambda x: x[1])\n",
    "        index = selected_locations.index(lowest_location)\n",
    "        selected_locations[index] = (lowest_location[0], lowest_location[1] - 1)\n",
    "        current_duration -= 1\n",
    "\n",
    "      if len(missing_locations) != 0:\n",
    "        if current_duration == duration:\n",
    "          lowest_location = max(selected_locations, key=lambda x: x[1])\n",
    "          index = selected_locations.index(lowest_location)\n",
    "          selected_locations[index] = (lowest_location[0], lowest_location[1] - 1)\n",
    "          current_duration -= 1\n",
    "\n",
    "          selected_locations.append((missing_locations[0], 1))\n",
    "          location_days[missing_locations[0]] += 1\n",
    "          current_duration += 1\n",
    "          missing_locations.pop(0)\n",
    "        else:\n",
    "          selected_locations.append((missing_locations[0], 1))\n",
    "          location_days[missing_locations[0]] += 1\n",
    "          current_duration += 1\n",
    "          missing_locations.pop(0)\n",
    "    return list(filter(lambda x: x[1] > 0, selected_locations))\n",
    "\n",
    "selected_locations = find_best_tour_with_days(\"iternary 1(in).csv\", locations, duration)\n",
    "print(\"Final List with days\")\n",
    "selected_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortest path calculation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shortest Path:\n",
      "kandy -> nuwara eliya -> bentota -> colombo\n",
      "Total Distance: 199.61 km\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import itertools\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "def geocodes(city):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"app1/1.0 (ashen@example.com)\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(f\"https://nominatim.openstreetmap.org/search?q={city}&format=json\", headers=headers)\n",
    "        \n",
    "        data = json.loads(response.content)\n",
    "        if data:\n",
    "            latitude = float(data[0][\"lat\"])\n",
    "            longitude = float(data[0][\"lon\"])\n",
    "            return latitude, longitude\n",
    "        else:\n",
    "            print(f\"No coordinates found for {city}\")\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding {city}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def calculate_distances(selected_locations):\n",
    "    coordinates = {}\n",
    "    for location, *_ in selected_locations:\n",
    "        lat, lon = geocodes(location)\n",
    "        if lat is not None and lon is not None:\n",
    "            coordinates[location] = (lat, lon)\n",
    "        else:\n",
    "            print(f\"Could not find coordinates for {location}\")\n",
    "            return None\n",
    "    \n",
    "    distances = {}\n",
    "    for i in range(len(selected_locations)):\n",
    "        for j in range(i + 1, len(selected_locations)):\n",
    "            loc1, *_ = selected_locations[i]\n",
    "            loc2, *_ = selected_locations[j]\n",
    "            distance = geodesic(coordinates[loc1], coordinates[loc2]).km\n",
    "            distances[(loc1, loc2)] = distance\n",
    "            distances[(loc2, loc1)] = distance  # Add reverse direction\n",
    "    \n",
    "    return distances, coordinates\n",
    "\n",
    "def find_shortest_path(selected_locations):\n",
    "    # Check if Colombo is in the locations\n",
    "    colombo_exists = any(loc == \"colombo\" for loc, *_ in selected_locations)\n",
    "    \n",
    "    # If Colombo is not in the list, add it\n",
    "    if not colombo_exists:\n",
    "        selected_locations.insert(0, (\"colombo\", 1))\n",
    "    \n",
    "    # Calculate distances between locations\n",
    "    distances_result = calculate_distances(selected_locations)\n",
    "    \n",
    "    if distances_result is None:\n",
    "        return None, None\n",
    "    \n",
    "    distances, coordinates = distances_result\n",
    "    \n",
    "    locations = [loc for loc, *_ in selected_locations]\n",
    "    \n",
    "    # Ensure Colombo is the first location\n",
    "    start_location = \"colombo\"\n",
    "    locations.remove(start_location)\n",
    "    \n",
    "    # Try all possible permutations of remaining locations\n",
    "    shortest_distance = float('inf')\n",
    "    shortest_path = None\n",
    "    \n",
    "    for path in itertools.permutations(locations):\n",
    "        full_path = (start_location,) + path  # Include Colombo at the start\n",
    "        \n",
    "        total_distance = 0\n",
    "        for i in range(len(full_path) - 1):\n",
    "            total_distance += distances.get((full_path[i], full_path[i + 1]), float('inf'))\n",
    "        \n",
    "        if total_distance < shortest_distance:\n",
    "            shortest_distance = total_distance\n",
    "            shortest_path = full_path\n",
    "    \n",
    "    return shortest_path, shortest_distance\n",
    "\n",
    "path, distance = find_shortest_path(selected_locations)\n",
    "\n",
    "if path and distance:\n",
    "    print(\"\\nShortest Path:\")\n",
    "    print(\" -> \".join(reversed(path)))\n",
    "    print(f\"Total Distance: {distance:.2f} km\")\n",
    "else:\n",
    "    print(\"Could not find a valid path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just extracting the activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location\n",
      "colombo         [colombo city tour & shopping , departure airp...\n",
      "kandy           [pinnawela elephant orphanage, cultural dance ...\n",
      "nuwara eliya    [kandy temple , peradeniya botanical gardens, ...\n",
      "Name: activity, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colombo': ['colombo city tour & shopping ',\n",
       "  'departure airport drop',\n",
       "  'lotus tower'],\n",
       " 'kandy': ['pinnawela elephant orphanage',\n",
       "  'cultural dance show ',\n",
       "  'kandy temple'],\n",
       " 'nuwara eliya': ['kandy temple ',\n",
       "  'peradeniya botanical gardens',\n",
       "  'gem museum']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itinerary['location'] = itinerary['location'].str.lower()\n",
    "itinerary['activity'] = itinerary['activity'].str.lower()  # Apply lowercase to 'activity' as well\n",
    "\n",
    "\n",
    "itinerary = itinerary.drop_duplicates(subset=['location', 'activity'])\n",
    "itinerary = itinerary.dropna(subset=['location', 'activity'])\n",
    "\n",
    "path = [p.lower() for p in path]\n",
    "\n",
    "grouped_activities = itinerary.groupby(\"location\")[\"activity\"].apply(list)\n",
    "grouped_activities = grouped_activities[grouped_activities.index.isin(path)]\n",
    "print(grouped_activities)\n",
    "\n",
    "# Create a dictionary with at most 3 activities per location\n",
    "location_dict = {location: activities[:3] for location, activities in grouped_activities.items()}\n",
    "\n",
    "location_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colombo', 'bentota', 'nuwara eliya', 'kandy']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting reportlab\n",
      "  Downloading reportlab-4.2.5-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting markdown\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\ashenr\\appdata\\local\\anaconda3\\envs\\py311\\lib\\site-packages (from reportlab) (11.0.0)\n",
      "Collecting chardet (from reportlab)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Downloading reportlab-4.2.5-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 441.3 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 588.4 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 588.4 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.3/1.9 MB 762.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/1.9 MB 822.3 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/1.9 MB 822.3 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/1.9 MB 818.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 808.4 kB/s eta 0:00:00\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: soupsieve, markdown, chardet, reportlab, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 chardet-5.2.0 markdown-3.7 reportlab-4.2.5 soupsieve-2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install reportlab markdown beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from reportlab.lib import colors\n",
    "# from reportlab.lib.pagesizes import letter, landscape\n",
    "# from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "# from reportlab.lib.units import inch\n",
    "# from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle, KeepTogether\n",
    "# from reportlab.pdfgen import canvas\n",
    "# from bs4 import BeautifulSoup\n",
    "# import markdown\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "# import os\n",
    "\n",
    "# class PDFWithHeaderFooter(SimpleDocTemplate):\n",
    "#     def __init__(self, filename, logo_path=None, **kwargs):\n",
    "#         SimpleDocTemplate.__init__(self, filename, **kwargs)\n",
    "#         self.page_count = 0\n",
    "#         self.logo_path = logo_path\n",
    "        \n",
    "#     def beforePage(self):\n",
    "#         self.page_count += 1\n",
    "#         self.canv.saveState()\n",
    "        \n",
    "#         # Only draw logo if path exists and is valid\n",
    "#         if self.logo_path and os.path.exists(self.logo_path):\n",
    "#             self.canv.drawImage(self.logo_path, 40, letter[1] - 50, width=1*inch, height=0.5*inch)\n",
    "        \n",
    "#         # Header setup\n",
    "#         self.canv.setFillColor(colors.HexColor('#2C3E50'))\n",
    "#         self.canv.setFont(\"Helvetica\", 14)\n",
    "#         self.canv.drawString(letter[0] - 200, letter[1] - 30, \n",
    "#                            f\"Generated: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "#         self.canv.setStrokeColor(colors.HexColor('#BDC3C7'))\n",
    "#         self.canv.line(40, letter[1] - 60, letter[0], letter[1] - 60)\n",
    "        \n",
    "#         # Footer setup\n",
    "#         self.canv.setFont(\"Helvetica\", 14)\n",
    "#         self.canv.drawString(letter[0]/2 - 20, 30, f\"Page {self.page_count}\")\n",
    "#         self.canv.drawString(40, 30, \"Confidential\")\n",
    "#         self.canv.line(0, 50, letter[0]+100, 50)\n",
    "#         self.canv.restoreState()\n",
    "\n",
    "# def wrap_header(header, max_length=1):\n",
    "#     \"\"\"Wrap long headers into multiple lines\"\"\"\n",
    "#     if not header:\n",
    "#         return \"\"\n",
    "#     words = str(header).split()\n",
    "#     lines = []\n",
    "#     current_line = []\n",
    "    \n",
    "#     for word in words:\n",
    "#         if len(' '.join(current_line + [word])) <= max_length:\n",
    "#             current_line.append(word)\n",
    "#         else:\n",
    "#             if current_line:\n",
    "#                 lines.append(' '.join(current_line))\n",
    "#             current_line = [word]\n",
    "    \n",
    "#     if current_line:\n",
    "#         lines.append(' '.join(current_line))\n",
    "    \n",
    "#     return '\\n'.join(lines)\n",
    "\n",
    "# def process_markdown_tables(markdown_text):\n",
    "#     try:\n",
    "#         html = markdown.markdown(markdown_text, extensions=['tables'])\n",
    "#         soup = BeautifulSoup(html, 'html.parser')\n",
    "#         tables = soup.find_all('table')\n",
    "        \n",
    "#         if not tables:\n",
    "#             return None\n",
    "            \n",
    "#         all_table_data = []\n",
    "#         for table in tables:\n",
    "#             data = []\n",
    "#             headers = [wrap_header(th.get_text().strip()) for th in table.find_all('th')]\n",
    "#             if not headers:  # Skip tables without headers\n",
    "#                 continue\n",
    "                \n",
    "#             data.append(headers)\n",
    "            \n",
    "#             for row in table.find_all('tr')[1:]:\n",
    "#                 row_data = [td.get_text().strip() for td in row.find_all('td')]\n",
    "#                 if len(row_data) == len(headers):  # Only add rows that match header count\n",
    "#                     data.append(row_data)\n",
    "                \n",
    "#             if len(data) > 1:  # Only add tables with data rows\n",
    "#                 all_table_data.append(data)\n",
    "            \n",
    "#         return all_table_data\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing markdown tables: {str(e)}\")\n",
    "#         return None\n",
    "\n",
    "# def create_pdf_report(content_json, output_file, logo_path=None):\n",
    "#     try:\n",
    "#         # Validate input\n",
    "#         if not isinstance(content_json, dict) or \"Report\" not in content_json:\n",
    "#             raise ValueError(\"Invalid content_json format\")\n",
    "            \n",
    "#         doc = PDFWithHeaderFooter(\n",
    "#             output_file,\n",
    "#             logo_path=logo_path,\n",
    "#             pagesize=landscape(letter),\n",
    "#             topMargin=1.3*inch,\n",
    "#             bottomMargin=1*inch,\n",
    "#             leftMargin=0.5*inch,\n",
    "#             rightMargin=0.5*inch\n",
    "#         )\n",
    "        \n",
    "#         styles = getSampleStyleSheet()\n",
    "#         title_style = ParagraphStyle(\n",
    "#             'CustomTitle',\n",
    "#             parent=styles['Heading1'],\n",
    "#             fontSize=18,\n",
    "#             spaceAfter=20,\n",
    "#             textColor=colors.HexColor('#2C3E50')\n",
    "#         )\n",
    "        \n",
    "#         body_style = ParagraphStyle(\n",
    "#             'CustomBody',\n",
    "#             parent=styles['Normal'],\n",
    "#             fontSize=14,\n",
    "#             spaceAfter=12,\n",
    "#             leading=14\n",
    "#         )\n",
    "        \n",
    "#         elements = []\n",
    "#         elements.append(Paragraph(\"Cracker Products Sales Analysis Report\", title_style))\n",
    "#         elements.append(Paragraph(\"January 2024\", styles['Heading2']))\n",
    "#         elements.append(Spacer(1, 20))\n",
    "        \n",
    "#         for section in content_json[\"Report\"]:\n",
    "#             section_elements = []\n",
    "#             for topic_key, topic_value in section.items():\n",
    "#                 if not isinstance(topic_value, str):\n",
    "#                     continue\n",
    "                    \n",
    "#                 if topic_key.startswith(\"topic\"):\n",
    "#                     section_elements.append(Paragraph(topic_value, title_style))\n",
    "#                 elif topic_key.startswith(\"description\"):\n",
    "#                     if \"topic2\" in section:  # Handle markdown tables\n",
    "#                         tables_data = process_markdown_tables(topic_value)\n",
    "#                         if tables_data:\n",
    "#                             for table_data in tables_data:\n",
    "#                                 available_width = doc.width\n",
    "#                                 col_count = len(table_data[0])\n",
    "#                                 col_widths = [available_width/col_count] * col_count\n",
    "                                \n",
    "#                                 table = Table(table_data, repeatRows=1, colWidths=col_widths)\n",
    "#                                 table.setStyle(TableStyle([\n",
    "#                                     ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2C3E50')),\n",
    "#                                     ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "#                                     ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "#                                     ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "#                                     ('FONTSIZE', (0, 0), (-1, 0), 11),\n",
    "#                                     ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "#                                     ('BACKGROUND', (0, 1), (-1, -1), colors.Color(0.95, 0.95, 0.95)),\n",
    "#                                     ('TEXTCOLOR', (0, 1), (-1, -1), colors.HexColor('#2C3E50')),\n",
    "#                                     ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n",
    "#                                     ('FONTSIZE', (0, 1), (-1, -1), 10),\n",
    "#                                     ('GRID', (0, 0), (-1, -1), 1, colors.Color(0.8, 0.8, 0.8)),\n",
    "#                                     ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "#                                     ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "#                                     ('PADDING', (0, 0), (-1, -1), 6),\n",
    "#                                 ]))\n",
    "#                                 section_elements.append(table)\n",
    "#                                 section_elements.append(Spacer(1, 20))\n",
    "#                     else:\n",
    "#                         try:\n",
    "#                             soup = BeautifulSoup(topic_value, 'html.parser')\n",
    "#                             for element in soup.children:\n",
    "#                                 if element.name == 'p':\n",
    "#                                     section_elements.append(Paragraph(str(element.decode_contents()), body_style))\n",
    "#                                 elif element.name == 'ul':\n",
    "#                                     for li in element.find_all('li'):\n",
    "#                                         section_elements.append(Paragraph(\"• \" + li.decode_contents(), body_style))\n",
    "#                         except Exception as e:\n",
    "#                             print(f\"Error processing HTML content: {str(e)}\")\n",
    "#                             section_elements.append(Paragraph(topic_value, body_style))\n",
    "                    \n",
    "#                     section_elements.append(Spacer(1, 10))\n",
    "            \n",
    "#             elements.append(KeepTogether(section_elements))\n",
    "        \n",
    "#         doc.build(elements)\n",
    "#         return True\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error creating PDF report: {str(e)}\")\n",
    "#         return False\n",
    "# # Use with your JSON content including markdown tables\n",
    "# # Example usage\n",
    "# report_content ={\n",
    "#     \"Report\": [\n",
    "#         {\n",
    "#             \"topic1\": \"Introduction\",\n",
    "#             \"description1\": \"<p>This report provides a comprehensive analysis of the sales performance of various cracker products for the month of January 2024. The analysis includes key metrics such as total gross sales, average weekly penetration, weekly retail selling price (RSP), out-of-stock (OOS) rates, fill rates, and promotional activities. The goal is to identify top-performing and underperforming products and derive actionable insights.</p>\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"topic2\": \"Data\",\n",
    "#             \"description1\": \"\"\"\n",
    "# The increase/decrease qty, RSP, distinct item count for the 'Ambient Liquid Milk' category between '2024-05-03' and '2024-05-17'?\n",
    "\n",
    "# | week_starting | stg_item_category_desc_txt | total_weekly_gross_sales | total_weekly_unit_sales | average_weekly_rsp | weekly_distinct_item_count | pct_change_gross_sales | pct_change_unit_sales | pct_change_average_rsp | change_in_distinct_item_count |\n",
    "# | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "# | 2024-05-03 | Ambient Liquid Milk | 5.660513E7 | 129562.0 | 644.638 | 36 | NULL | NULL | NULL | NULL |\n",
    "# | 2024-05-10 | Ambient Liquid Milk | 5.7065741E7 | 132682.0 | 644.814 | 36 | 0.008 | 0.024 | 0.0 | 0 |\n",
    "# | 2024-05-17 | Ambient Liquid Milk | 5.0448661E7 | 118116.0 | 660.699 | 37 | -0.116 | -0.11 | 0.025 | 1 |\n",
    "\n",
    "\n",
    "# The increase or decrease overall volume for the 'Ambient Liquid Milk' category between '2024-05-03' and '2024-05-17'?\n",
    "\n",
    "# | week_starting | unit_of_measure | total_weekly_volume | percentage_change |\n",
    "# | --- | --- | --- | --- |\n",
    "# | 2024-05-03 | L | 100502.44 | NULL |\n",
    "# | 2024-05-10 | L | 101524.7 | 1.02 |\n",
    "# | 2024-05-17 | L | 89952.56 | -11.4 |\n",
    "# \"\"\"\n",
    "#         },\n",
    "\n",
    "#         {\n",
    "#             \"topic3\": \"Answers to Key Questions\",\n",
    "#             \"description3\": \"<p>The analysis of the sales data for January 2024 reveals the following key insights:</p><ul><li><strong>Top Performing Products:</strong> The top-performing product is the 'MUNCHEE SUPER CREAM CRACKER 490G' with the highest total gross sales of 3,688,320.0 on the week starting 2024-01-19.</li><li><strong>Underperforming Products:</strong> The 'MALIBAN CRM CRACKER POCKET PACK 85G' consistently shows the lowest sales figures, with a total gross sales of 90.0 across multiple weeks.</li><li><strong>Out-of-Stock Rates:</strong> The 'MALIBAN CRACKERS THINS 95G' has the highest monthly OOS rate of 0.873 on the week starting 2024-01-05, indicating frequent stockouts.</li><li><strong>Fill Rates:</strong> The 'MUNCHEE SUPER CREAM CRACKER 490G' achieved a perfect fill rate of 1.0 on the week starting 2024-01-19, ensuring product availability.</li></ul>\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"topic4\": \"Key Insights & Analysis\",\n",
    "#             \"description4\": \"<p>Based on the data, several key insights can be drawn:</p><ul><li><strong>Sales Performance:</strong> The 'MUNCHEE SUPER CREAM CRACKER 490G' consistently performs well, indicating strong market demand and effective distribution strategies.</li><li><strong>Stock Management:</strong> High OOS rates for certain products like 'MALIBAN CRACKERS THINS 95G' suggest issues in inventory management that need to be addressed to prevent lost sales opportunities.</li><li><strong>Product Availability:</strong> Products with high fill rates, such as 'MUNCHEE SUPER CREAM CRACKER 490G', demonstrate efficient supply chain operations, ensuring customer satisfaction.</li><li><strong>Promotional Activities:</strong> The absence of promotional activities across all products suggests potential areas for growth through targeted marketing campaigns.</li></ul>\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"topic5\": \"Conclusion & Recommendations\",\n",
    "#             \"description5\": \"<p>In conclusion, the analysis highlights the importance of effective stock management and the potential benefits of promotional activities. The 'MUNCHEE SUPER CREAM CRACKER 490G' serves as a benchmark for successful product performance, while underperforming products like 'MALIBAN CRM CRACKER POCKET PACK 85G' require strategic interventions to boost sales. Recommendations include:</p><ul><li>Implementing targeted promotional campaigns to increase product visibility and sales.</li><li>Improving inventory management practices to reduce OOS rates and enhance product availability.</li><li>Conducting further analysis to identify factors contributing to the success of top-performing products and replicating these strategies across other product lines.</li></ul>\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"topic6\": \"Further Areas of Investigation\",\n",
    "#             \"description6\": \"<p>To validate the conclusions and recommendations, further areas of investigation include:</p><ul><li>Analyzing customer feedback and preferences to understand the factors driving product performance.</li><li>Conducting competitor analysis to identify market trends and opportunities for differentiation.</li><li>Evaluating the impact of promotional activities on sales performance through controlled experiments.</li><li>Assessing the effectiveness of supply chain operations and identifying areas for improvement to enhance product availability and reduce OOS rates.</li></ul>\"\n",
    "#         }\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# create_pdf_report(report_content, 'sales_analysis_report.pdf',logo_path=\"octave.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch, mm\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, KeepTogether\n",
    "from reportlab.pdfgen import canvas\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class PDFWithHeaderFooter(SimpleDocTemplate):\n",
    "    def __init__(self, filename, **kwargs):\n",
    "        SimpleDocTemplate.__init__(self, filename, **kwargs)\n",
    "        self.page_count = 0\n",
    "        \n",
    "    def beforePage(self):\n",
    "        self.page_count += 1\n",
    "        self.canv.saveState()\n",
    "        \n",
    "        # Header with logo\n",
    "        logo_path = \"octave.png\"\n",
    "        try:\n",
    "            self.canv.drawImage(logo_path, 20*mm, A4[1] - 25*mm, width=25*mm, height=12.5*mm)\n",
    "        except:\n",
    "            self.canv.setFont(\"Helvetica-Bold\", 20)\n",
    "            self.canv.drawString(20*mm, A4[1] - 25*mm, \"COMPANY\")\n",
    "        \n",
    "        # Header text\n",
    "        self.canv.setFont(\"Helvetica\", 9)\n",
    "        self.canv.drawString(A4[0] - 80*mm, A4[1] - 15*mm,\n",
    "                          f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "        \n",
    "        self.canv.line(20*mm, A4[1] - 30*mm, A4[0] - 20*mm, A4[1] - 30*mm)\n",
    "        \n",
    "        # Footer\n",
    "        self.canv.setFont(\"Helvetica\", 9)\n",
    "        footer_text = f\"Page {self.page_count}\"\n",
    "        self.canv.drawString(A4[0]/2 - 10*mm, 15*mm, footer_text)\n",
    "        self.canv.drawString(20*mm, 15*mm, \"Confidential\")\n",
    "        \n",
    "        self.canv.line(20*mm, 25*mm, A4[0] - 20*mm, 25*mm)\n",
    "        self.canv.restoreState()\n",
    "\n",
    "def process_markdown_tables(markdown_text):\n",
    "    \"\"\"Process markdown text and extract tables\"\"\"\n",
    "    html = markdown.markdown(markdown_text, extensions=['tables'])\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    tables = []\n",
    "    for table in soup.find_all('table'):\n",
    "        data = []\n",
    "        headers = [Paragraph(th.get_text().strip(), ParagraphStyle('Header', wordWrap='CJK')) \n",
    "                  for th in table.find_all('th')]\n",
    "        if headers:\n",
    "            data.append(headers)\n",
    "        \n",
    "        for row in table.find_all('tr'):\n",
    "            if not row.find_all('th'):  # Skip header row\n",
    "                row_data = [Paragraph(td.get_text().strip(), ParagraphStyle('Cell', wordWrap='CJK')) \n",
    "                           for td in row.find_all('td')]\n",
    "                if row_data:\n",
    "                    data.append(row_data)\n",
    "        \n",
    "        tables.append(data)\n",
    "        table.decompose()\n",
    "    \n",
    "    return tables\n",
    "\n",
    "def process_html_content(html_content):\n",
    "    \"\"\"Process HTML content and convert to reportlab paragraphs\"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    elements = []\n",
    "    styles = getSampleStyleSheet()\n",
    "    \n",
    "    for element in soup.find_all(['p', 'ul']):\n",
    "        if element.name == 'p':\n",
    "            elements.append(Paragraph(str(element), styles['Normal']))\n",
    "        elif element.name == 'ul':\n",
    "            for li in element.find_all('li'):\n",
    "                bullet_text = f\"• {li.get_text()}\"\n",
    "                elements.append(Paragraph(bullet_text, styles['Normal']))\n",
    "    \n",
    "    return elements\n",
    "\n",
    "def create_table_style():\n",
    "    \"\"\"Create consistent table style\"\"\"\n",
    "    return TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, 0), 12),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
    "        ('TEXTCOLOR', (0, 1), (-1, -1), colors.black),\n",
    "        ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n",
    "        ('FONTSIZE', (0, 1), (-1, -1), 10),\n",
    "        ('GRID', (0, 0), (-1, -1), 1, colors.black),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('PADDING', (0, 0), (-1, -1), 6),\n",
    "        ('WORDWRAP', (0, 0), (-1, -1), True),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 3*mm),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 3*mm),\n",
    "    ])\n",
    "\n",
    "def generate_sales_report_pdf(json_data,topics, output_pdf):\n",
    "    # Calculate usable width (A4 width minus margins)\n",
    "    margin = 20*mm  # 20mm margins on each side\n",
    "    usable_width = A4[0] - 2*margin\n",
    "    \n",
    "    doc = PDFWithHeaderFooter(\n",
    "        output_pdf,\n",
    "        pagesize=A4,\n",
    "        topMargin=35*mm,\n",
    "        bottomMargin=30*mm,\n",
    "        leftMargin=margin,\n",
    "        rightMargin=margin\n",
    "    )\n",
    "    \n",
    "    styles = getSampleStyleSheet()\n",
    "    elements = []\n",
    "    \n",
    "    # Title\n",
    "    title_style = ParagraphStyle(\n",
    "        'CustomTitle',\n",
    "        parent=styles['Title'],\n",
    "        fontSize=24,\n",
    "        spaceAfter=30\n",
    "    )\n",
    "    elements.append(Paragraph(\"Sales Performance Analysis Report\", title_style))\n",
    "    \n",
    "    # Topic style\n",
    "    topic_style = ParagraphStyle(\n",
    "        'TopicStyle',\n",
    "        parent=styles['Heading1'],\n",
    "        fontSize=18,\n",
    "        spaceAfter=20,\n",
    "        spaceBefore=30\n",
    "    )\n",
    "    \n",
    "    for i, section in enumerate(json_data, 1):\n",
    "        # Get the topic and description keys\n",
    "        topic_key = next(key for key in section.keys() if key.startswith('topic'))\n",
    "        desc_key = next(key for key in section.keys() if key.startswith('description'))\n",
    "        \n",
    "        # Create section elements\n",
    "        section_elements = []\n",
    "        \n",
    "        # Add topic heading\n",
    "        topic_text = section[topic_key]\n",
    "        section_elements.append(Paragraph(topic_text, topic_style))\n",
    "        \n",
    "        description = section[desc_key]\n",
    "        \n",
    "        # Check if content is markdown (contains table markers)\n",
    "        if '|' in description and '---' in description:\n",
    "            # Process markdown content\n",
    "            tables = process_markdown_tables(description)\n",
    "            # Add tables\n",
    "            k = 0\n",
    "            for table_data in tables:\n",
    "\n",
    "\n",
    "                if table_data:                        \n",
    "                    section_elements.append(Paragraph(topics[k], styles['Normal']))\n",
    "                    k = k+1\n",
    "\n",
    "                    # Calculate column widths to fit within usable width\n",
    "                    num_cols = len(table_data[0])\n",
    "                    col_width = usable_width / num_cols\n",
    "                    col_widths = [col_width] * num_cols\n",
    "                    \n",
    "                    table = Table(table_data, colWidths=col_widths, repeatRows=1)\n",
    "                    table.setStyle(create_table_style())\n",
    "                    # Always wrap tables in KeepTogether\n",
    "                    section_elements.append(KeepTogether(table))\n",
    "                    section_elements.append(Spacer(1, 20))\n",
    "        else:\n",
    "            # Process HTML content\n",
    "            html_elements = process_html_content(description)\n",
    "            section_elements.extend(html_elements)\n",
    "        \n",
    "        section_elements.append(Spacer(1, 20))\n",
    "        \n",
    "        # If it's the second section, don't wrap in KeepTogether\n",
    "        if i == 2:\n",
    "            elements.extend(section_elements)\n",
    "        else:\n",
    "            # Wrap all other sections in KeepTogether\n",
    "            elements.append(KeepTogether(section_elements))\n",
    "    \n",
    "    doc.build(elements)\n",
    "if __name__ == \"__main__\":\n",
    "    json_data = [\n",
    "        {\n",
    "            \"topic1\": \"Introduction\",\n",
    "            \"description1\": \"<p>This report provides a comprehensive analysis of the sales performance of various cracker products for the month of January 2024. The analysis includes key metrics such as total gross sales, average weekly penetration, weekly retail selling price (RSP), out-of-stock (OOS) rates, fill rates, and promotional activities. The goal is to identify top-performing and underperforming products and derive actionable insights.</p>\"\n",
    "        },\n",
    "         {\n",
    "            \"topic3\": \"Answers to Key Questions\",\n",
    "            \"description3\": \"<p>The analysis of the sales data for January 2024 reveals the following key insights:</p><ul><li><strong>Top Performing Products:</strong> The top-performing product is the 'MUNCHEE SUPER CREAM CRACKER 490G' with the highest total gross sales of 3,688,320.0 on the week starting 2024-01-19.</li><li><strong>Underperforming Products:</strong> The 'MALIBAN CRM CRACKER POCKET PACK 85G' consistently shows the lowest sales figures, with a total gross sales of 90.0 across multiple weeks.</li><li><strong>Out-of-Stock Rates:</strong> The 'MALIBAN CRACKERS THINS 95G' has the highest monthly OOS rate of 0.873 on the week starting 2024-01-05, indicating frequent stockouts.</li><li><strong>Fill Rates:</strong> The 'MUNCHEE SUPER CREAM CRACKER 490G' achieved a perfect fill rate of 1.0 on the week starting 2024-01-19, ensuring product availability.</li></ul>\"\n",
    "        },\n",
    "        {\n",
    "            \"topic2\": \"Data Representation\",\n",
    "            \"description1\": \"\"\" \n",
    "\n",
    "| week_starting | stg_item_category_desc_txt | total_weekly_gross_sales | total_weekly_unit_sales | average_weekly_rsp | weekly_distinct_item_count | pct_change_gross_sales | pct_change_unit_sales | pct_change_average_rsp | change_in_distinct_item_count |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 2024-05-03 | Ambient Liquid Milk | 5.660513E7 | 129562.0 | 644.638 | 36 | NULL | NULL | NULL | NULL |\n",
    "| 2024-05-10 | Ambient Liquid Milk | 5.7065741E7 | 132682.0 | 644.814 | 36 | 0.008 | 0.024 | 0.0 | 0 |\n",
    "| 2024-05-17 | Ambient Liquid Milk | 5.0448661E7 | 118116.0 | 660.699 | 37 | -0.116 | -0.11 | 0.025 | 1 |\n",
    "\n",
    "| week_starting | stg_item_category_desc_txt | total_weekly_gross_sales | total_weekly_unit_sales | average_weekly_rsp | weekly_distinct_item_count | pct_change_gross_sales | pct_change_unit_sales | pct_change_average_rsp | change_in_distinct_item_count |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 2024-05-03 | Ambient Liquid Milk | 5.660513E7 | 129562.0 | 644.638 | 36 | NULL | NULL | NULL | NULL |\n",
    "| 2024-05-10 | Ambient Liquid Milk | 5.7065741E7 | 132682.0 | 644.814 | 36 | 0.008 | 0.024 | 0.0 | 0 |\n",
    "| 2024-05-17 | Ambient Liquid Milk | 5.0448661E7 | 118116.0 | 660.699 | 37 | -0.116 | -0.11 | 0.025 | 1 |\n",
    "\n",
    "\n",
    "| week_starting | stg_item_category_desc_txt | total_weekly_gross_sales | total_weekly_unit_sales | average_weekly_rsp | weekly_distinct_item_count | pct_change_gross_sales | pct_change_unit_sales | pct_change_average_rsp | change_in_distinct_item_count |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 2024-05-03 | Ambient Liquid Milk | 5.660513E7 | 129562.0 | 644.638 | 36 | NULL | NULL | NULL | NULL |\n",
    "| 2024-05-10 | Ambient Liquid Milk | 5.7065741E7 | 132682.0 | 644.814 | 36 | 0.008 | 0.024 | 0.0 | 0 |\n",
    "| 2024-05-17 | Ambient Liquid Milk | 5.0448661E7 | 118116.0 | 660.699 | 37 | -0.116 | -0.11 | 0.025 | 1 |\n",
    "\n",
    "| week_starting | unit_of_measure | total_weekly_volume | percentage_change |\n",
    "| --- | --- | --- | --- |\n",
    "| 2024-05-03 | L | 100502.44 | NULL |\n",
    "| 2024-05-10 | L | 101524.7 | 1.02 |\n",
    "| 2024-05-17 | L | 89952.56 | -11.4 |\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"topic3\": \"Answers to Key Questions\",\n",
    "            \"description3\": \"<p>The analysis of the sales data for January 2024 reveals the following key insights:</p><ul><li><strong>Top Performing Products:</strong> The top-performing product is the 'MUNCHEE SUPER CREAM CRACKER 490G' with the highest total gross sales of 3,688,320.0 on the week starting 2024-01-19.</li><li><strong>Underperforming Products:</strong> The 'MALIBAN CRM CRACKER POCKET PACK 85G' consistently shows the lowest sales figures, with a total gross sales of 90.0 across multiple weeks.</li><li><strong>Out-of-Stock Rates:</strong> The 'MALIBAN CRACKERS THINS 95G' has the highest monthly OOS rate of 0.873 on the week starting 2024-01-05, indicating frequent stockouts.</li><li><strong>Fill Rates:</strong> The 'MUNCHEE SUPER CREAM CRACKER 490G' achieved a perfect fill rate of 1.0 on the week starting 2024-01-19, ensuring product availability.</li></ul>\"\n",
    "        },\n",
    "        {\n",
    "            \"topic4\": \"Key Insights & Analysis\",\n",
    "            \"description4\": \"<p>Based on the data, several key insights can be drawn:</p><ul><li><strong>Sales Performance:</strong> The 'MUNCHEE SUPER CREAM CRACKER 490G' consistently performs well, indicating strong market demand and effective distribution strategies.</li><li><strong>Stock Management:</strong> High OOS rates for certain products like 'MALIBAN CRACKERS THINS 95G' suggest issues in inventory management that need to be addressed to prevent lost sales opportunities.</li><li><strong>Product Availability:</strong> Products with high fill rates, such as 'MUNCHEE SUPER CREAM CRACKER 490G', demonstrate efficient supply chain operations, ensuring customer satisfaction.</li><li><strong>Promotional Activities:</strong> The absence of promotional activities across all products suggests potential areas for growth through targeted marketing campaigns.</li></ul>\"\n",
    "        },\n",
    "        {\n",
    "            \"topic5\": \"Conclusion & Recommendations\",\n",
    "            \"description5\": \"<p>In conclusion, the analysis highlights the importance of effective stock management and the potential benefits of promotional activities. The 'MUNCHEE SUPER CREAM CRACKER 490G' serves as a benchmark for successful product performance, while underperforming products like 'MALIBAN CRM CRACKER POCKET PACK 85G' require strategic interventions to boost sales. Recommendations include:</p><ul><li>Implementing targeted promotional campaigns to increase product visibility and sales.</li><li>Improving inventory management practices to reduce OOS rates and enhance product availability.</li><li>Conducting further analysis to identify factors contributing to the success of top-performing products and replicating these strategies across other product lines.</li></ul>\"\n",
    "        },\n",
    "        {\n",
    "            \"topic6\": \"Further Areas of Investigation\",\n",
    "            \"description6\": \"<p>To validate the conclusions and recommendations, further areas of investigation include:</p><ul><li>Analyzing customer feedback and preferences to understand the factors driving product performance.</li><li>Conducting competitor analysis to identify market trends and opportunities for differentiation.</li><li>Evaluating the impact of promotional activities on sales performance through controlled experiments.</li><li>Assessing the effectiveness of supply chain operations and identifying areas for improvement to enhance product availability and reduce OOS rates.</li></ul>\"\n",
    "        }\n",
    "    ]\n",
    "    topics = [\"topic1\", \"topic2\", \"topic3\", \"topic4\"]\n",
    "    # equivalent to\n",
    "\n",
    "\n",
    "    # json_data = json.load(json_data)\n",
    "    generate_sales_report_pdf(json_data,topics, \"sales_report.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object ReportPDFGenerator.generate_pdf at 0x000001ACEDC52CA0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import tempfile\n",
    "import json\n",
    "import markdown2\n",
    "from flask import jsonify, send_file\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import A4, landscape\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch, mm\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, KeepTogether\n",
    "from reportlab.pdfgen import canvas\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "class PDFWithHeaderFooter(SimpleDocTemplate):\n",
    "    def __init__(self, filename, **kwargs):\n",
    "        SimpleDocTemplate.__init__(self, filename, **kwargs)\n",
    "        self.page_count = 0\n",
    "        self.logo_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'logo.png')\n",
    "        \n",
    "    def beforePage(self):\n",
    "        self.page_count += 1\n",
    "        self.canv.saveState()\n",
    "        \n",
    "        # Logo\n",
    "        if os.path.exists(self.logo_path):\n",
    "            self.canv.drawImage(self.logo_path, 15*mm, A4[0] - 15*mm, width=20*mm, height=10*mm, preserveAspectRatio=True)\n",
    "        \n",
    "        self.canv.setFont(\"Helvetica-Bold\", 10)  \n",
    "        self.canv.setFillColor(colors.black)\n",
    "        self.canv.drawCentredString(A4[1]/2, A4[0] - 13*mm, \"Confidential Report\")\n",
    "        \n",
    "        self.canv.setLineWidth(0.5)\n",
    "        self.canv.line(15*mm, A4[0] - 15*mm, A4[1] - 15*mm, A4[0] - 15*mm)\n",
    "        \n",
    "        \n",
    "        # Footer\n",
    "        self.canv.setFont(\"Helvetica\", 8)\n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        self.canv.drawString(30*mm, 10*mm, f\"Generated on {current_date}\")\n",
    "        self.canv.drawCentredString(A4[1]/2, 10*mm, \"© OCTAVE, John Keells Holdings PLC.\")\n",
    "        self.canv.drawRightString(A4[1] - 30*mm, 10*mm, f\"Page {self.page_count}\")\n",
    "        \n",
    "        self.canv.restoreState()\n",
    "\n",
    "class ReportPDFGenerator:\n",
    "    @staticmethod\n",
    "    def process_markdown_content(markdown_content):\n",
    "        if isinstance(markdown_content, str):\n",
    "            try:\n",
    "                markdown_content = json.loads(markdown_content)\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise ValueError(f\"Invalid report format: {str(e)}\")\n",
    "\n",
    "        if \"Report\" not in markdown_content:\n",
    "            raise ValueError(\"Invalid report structure\")\n",
    "\n",
    "        report_sections = []\n",
    "        for section in markdown_content[\"Report\"]:\n",
    "            for topic_num in range(1, 7):\n",
    "                topic_key = f\"topic{topic_num}\"\n",
    "                desc_key = f\"description{topic_num}\"\n",
    "                \n",
    "                if topic_key in section:\n",
    "                    section_html = f'<div class=\"section\"><h2>{section[topic_key]}</h2>'\n",
    "                    description = section[desc_key]\n",
    "                    \n",
    "                    if '|' in description and '---' in description:\n",
    "                        description = markdown2.markdown(description, extras=['tables'])\n",
    "                    elif not description.startswith('<'):\n",
    "                        description = markdown2.markdown(description)\n",
    "                    \n",
    "                    section_html += f'<div class=\"content\">{description}</div></div>'\n",
    "                    report_sections.append(section_html)\n",
    "\n",
    "        return report_sections\n",
    "\n",
    "    @staticmethod\n",
    "    async def generate_pdf(report):\n",
    "        try:\n",
    "            report_sections = ReportPDFGenerator.process_markdown_content(report[\"markdown_report\"])\n",
    "            \n",
    "            # Create temporary PDF file\n",
    "            with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as pdf_file:\n",
    "                pdf_path = pdf_file.name\n",
    "                \n",
    "                # Initialize PDF doc\n",
    "                doc = PDFWithHeaderFooter(\n",
    "                    pdf_path,\n",
    "                    pagesize=landscape(A4),\n",
    "                    rightMargin=15*mm,\n",
    "                    leftMargin=15*mm,\n",
    "                    topMargin=20*mm,\n",
    "                    bottomMargin=25*mm\n",
    "                )\n",
    "                \n",
    "                styles = getSampleStyleSheet()\n",
    "                title_style = ParagraphStyle(\n",
    "                    'CustomTitle',\n",
    "                    parent=styles['Heading1'],\n",
    "                    fontSize=24,\n",
    "                    alignment=1,\n",
    "                    spaceAfter=30\n",
    "                )\n",
    "                \n",
    "                elements = []\n",
    "                elements.append(Paragraph(report[\"title\"], title_style))\n",
    "                \n",
    "                def process_list_item(item, level=0, list_type='ul'):\n",
    "                    bullet = '•' if list_type == 'ul' else f\"{item.parent.index(item) + 1}.\"\n",
    "                    indent = level * 20  \n",
    "                    \n",
    "                    list_text = f\"{bullet} {item.get_text(separator=' ', strip=True)}\"\n",
    "                    elements.append(Paragraph(list_text, ParagraphStyle(\n",
    "                        'List',\n",
    "                        parent=styles['Normal'],\n",
    "                        leftIndent=indent + 20,\n",
    "                        spaceBefore=3,\n",
    "                        spaceAfter=3\n",
    "                    )))\n",
    "                    \n",
    "                    # Process nested lists\n",
    "                    nested_lists = item.find_all(['ul', 'ol'], recursive=False)\n",
    "                    for nested_list in nested_lists:\n",
    "                        for nested_item in nested_list.find_all('li', recursive=False):\n",
    "                            process_list_item(nested_item, level + 1, nested_list.name)\n",
    "\n",
    "                for section in report_sections:\n",
    "                    soup = BeautifulSoup(section, 'html.parser')\n",
    "                    \n",
    "                    if soup.h2:\n",
    "                        elements.append(Paragraph(soup.h2.text, styles['Heading2']))\n",
    "                    \n",
    "                    content_div = soup.find('div', class_='content')\n",
    "                    if content_div:\n",
    "                        current_element = content_div.find_next()\n",
    "                        while current_element:\n",
    "                            if current_element.name == 'table':\n",
    "                                # Handle table as before\n",
    "                                data = []\n",
    "                                for row in current_element.find_all('tr'):\n",
    "                                    data.append([cell.text.strip() for cell in row.find_all(['th', 'td'])])\n",
    "                                \n",
    "                                if data:\n",
    "                                    # Calculate available width (page width minus margins)\n",
    "                                    available_width = doc.width\n",
    "                                    \n",
    "                                    # Count number of columns\n",
    "                                    num_cols = len(data[0])\n",
    "                                    \n",
    "                                    # Calculate column widths based on content\n",
    "                                    col_widths = []\n",
    "                                    for col in range(num_cols):\n",
    "                                        # Get maximum width needed for this column\n",
    "                                        col_data = [str(row[col]) for row in data]\n",
    "                                        max_width = max(len(text) for text in col_data) * 5  # Approximate width based on text length\n",
    "                                        \n",
    "                                        # Ensure minimum width for readability\n",
    "                                        min_width = 100  # minimum width in points\n",
    "                                        col_widths.append(max(max_width, min_width))\n",
    "                                    \n",
    "                                    # Adjust widths to fit available space\n",
    "                                    total_width = sum(col_widths)\n",
    "                                    scale_factor = available_width / total_width\n",
    "                                    col_widths = [width * scale_factor for width in col_widths]\n",
    "\n",
    "                                    pdf_table = Table(data, repeatRows=1, colWidths=col_widths)\n",
    "                                    pdf_table.setStyle(TableStyle([\n",
    "                                        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "                                        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "                                        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "                                        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "                                        ('FONTSIZE', (0, 0), (-1, 0), 10),\n",
    "                                        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "                                        ('TOPPADDING', (0, 0), (-1, 0), 12),\n",
    "                                        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "                                        ('TEXTCOLOR', (0, 1), (-1, -1), colors.black),\n",
    "                                        ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n",
    "                                        ('FONTSIZE', (0, 1), (-1, -1), 8),\n",
    "                                        ('GRID', (0, 0), (-1, -1), 1, colors.black),\n",
    "                                        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "                                        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "                                        ('WORDWRAP', (0, 0), (-1, -1), True),\n",
    "                                        ('LEFTPADDING', (0, 0), (-1, -1), 6),\n",
    "                                        ('RIGHTPADDING', (0, 0), (-1, -1), 6),\n",
    "                                    ]))\n",
    "                                        \n",
    "                                    elements.append(KeepTogether([\n",
    "                                        pdf_table,\n",
    "                                        Spacer(1, 20)\n",
    "                                    ]))\n",
    "                            elif current_element.name in ['ul', 'ol']:\n",
    "                                for li in current_element.find_all('li', recursive=False):\n",
    "                                    process_list_item(li, level=0, list_type=current_element.name)\n",
    "                                elements.append(Spacer(1, 6))\n",
    "                            \n",
    "                            else:\n",
    "                                if current_element.name:  \n",
    "                                    text = current_element.get_text(separator=' ', strip=True)\n",
    "                                else:  \n",
    "                                    text = str(current_element).strip()\n",
    "                                    \n",
    "                                if text:\n",
    "                                    style = styles['Normal']\n",
    "                                    if current_element.name == 'strong' or current_element.name == 'b':\n",
    "                                        style = ParagraphStyle(\n",
    "                                            'Bold',\n",
    "                                            parent=styles['Normal'],\n",
    "                                            fontName='Helvetica-Bold'\n",
    "                                        )\n",
    "                                    elif current_element.name == 'em' or current_element.name == 'i':\n",
    "                                        style = ParagraphStyle(\n",
    "                                            'Italic',\n",
    "                                            parent=styles['Normal'],\n",
    "                                            fontName='Helvetica-Oblique'\n",
    "                                        )\n",
    "                                    \n",
    "                                    elements.append(Paragraph(text, style))\n",
    "                            \n",
    "                            current_element = current_element.find_next_sibling()\n",
    "                        \n",
    "                        elements.append(Spacer(1, 12))\n",
    "                    \n",
    "                    elements.append(Spacer(1, 12))\n",
    "                \n",
    "                doc.build(elements)\n",
    "                \n",
    "                return send_file(\n",
    "                    pdf_path,\n",
    "                    mimetype='application/pdf',\n",
    "                    as_attachment=True,\n",
    "                    download_name=f\"{report['title']}.pdf\"\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating PDF: {str(e)}\")\n",
    "            raise \n",
    "\n",
    "json_data = '''{'id': 'cf94b38e-16ca-47f4-bd84-1604abeba52d', 'user_id': 'ashen.jkh@keells.com', 'title': 'Crackers Weekly Within Cat Analysis', 'product': 'Crackers', 'analysis_type': 'Within Category Analysis', 'markdown_report': '{\"Report\":[{\"description1\":\"<p>This report provides an analysis of the sales performance of Crackers over a three-week period in January 2024. The analysis includes unit sales, gross sales, retail selling price (RSP), distinct item count, and the impact of holidays on sales performance.</p>\",\"topic1\":\"Introduction\"},{\"description2\":\"\\\\nThe increase/decrease qty, RSP, distinct item count for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'?\\\\n\\\\n| week_starting | stg_item_category_desc_txt | total_weekly_gross_sales | total_weekly_unit_sales | average_weekly_rsp | weekly_distinct_item_count | pct_change_gross_sales | pct_change_unit_sales | pct_change_average_rsp | change_in_distinct_item_count |\\\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\\\n| 2024-01-05 | Crackers | 1.3170845E7 | 53368.0 | 217.233 | 23 | NULL | NULL | NULL | NULL |\\\\n| 2024-01-12 | Crackers | 1.3557499E7 | 54270.0 | 215.423 | 23 | 0.029 | 0.017 | -0.008 | 0 |\\\\n| 2024-01-19 | Crackers | 1.4305722E7 | 57030.0 | 213.55 | 22 | 0.055 | 0.051 | -0.009 | -1 |\\\\n\\\\n\\\\nThe increase or decrease overall volume for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'?\\\\n\\\\n| week_starting | unit_of_measure | total_weekly_volume | percentage_change |\\\\n| --- | --- | --- | --- |\\\\n| 2024-01-05 | KG | 16849.4 | NULL |\\\\n| 2024-01-12 | KG | 17373.94 | 3.11 |\\\\n| 2024-01-19 | KG | 18457.93 | 6.24 |\\\\n\\\\n\\\\nThe increase or decrease Nexus qty, penetration sales, WOP, FOP for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'?\\\\n\\\\n| week_starting | stg_item_category_desc_txt | nexus_weekly_unit_sales | nexus_weekly_penetration | nexus_weekly_wop | nexus_weekly_fop | nexus_weekly_unit_sales_pct_change | nexus_weekly_penetration_pct_change | nexus_weekly_wop_pct_change | nexus_average_weekly_fop_pct_change |\\\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\\\n| 2024-01-05 | Crackers | 46875.0 | 40165 | 1.131 | 1.019 | NULL | NULL | NULL | NULL |\\\\n| 2024-01-12 | Crackers | 48294.0 | 41534 | 1.134 | 1.019 | 3.027 | 3.408 | 0.239 | -0.082 |\\\\n| 2024-01-19 | Crackers | 50604.0 | 43689 | 1.126 | 1.019 | 4.783 | 5.189 | -0.671 | -0.002 |\\\\n\\\\n\\\\nThe increase or decrease Nexus volume for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'? \\\\n\\\\n| week_starting | unit_of_measure | total_weekly_volume | percentage_change |\\\\n| --- | --- | --- | --- |\\\\n| 2024-01-05 | KG | 14797.48 | NULL |\\\\n| 2024-01-12 | KG | 15467.16 | 4.53 |\\\\n| 2024-01-19 | KG | 16373.85 | 5.86 |\\\\n\\\\n\\\\nThe increase or decrease non-Nexus qty, WOP for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'? \\\\n\\\\n| week_starting | stg_item_category_desc_txt | non_nexus_weekly_unit_sales | non_nexus_weekly_wop | pct_change_non_nexus_weekly_unit_sales | pct_change_non_nexus_weekly_wop |\\\\n| --- | --- | --- | --- | --- | --- |\\\\n| 2024-01-05 | Crackers | 6493.0 | 1.068 | NULL | NULL |\\\\n| 2024-01-12 | Crackers | 5976.0 | 1.032 | -0.08 | -0.034 |\\\\n| 2024-01-19 | Crackers | 6426.0 | 1.08 | 0.075 | 0.047 |\\\\n\\\\n\\\\nThe changes in the OOS rate, SHD, and the number of item-outlet active instances for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'?\\\\n\\\\n| week_starting | stg_item_category_desc_txt | weekly_avg_stock_holding_days | weekly_avg_fill_rate | weekly_OOS_rate | aweekly_avg_stock_holding_days_pct | weekly_OOS_rate_pct | weekly_avg_fill_rate_pct |\\\\n| --- | --- | --- | --- | --- | --- | --- | --- |\\\\n| 2024-01-05 | Crackers | 25.701 | 0.941 | 0.144 | NULL | NULL | NULL |\\\\n| 2024-01-12 | Crackers | 24.083 | 0.984 | 0.172 | -0.063 | 0.194 | 0.045 |\\\\n| 2024-01-19 | Crackers | 23.805 | 1.0 | 0.202 | -0.012 | 0.174 | 0.017 |\\\\n\\\\n\\\\nThe change in promotion count or distribution of promotion types for the  \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'? \\\\n\\\\n| week_starting | stg_item_category_desc_txt | stg_promo_type_txt | weekly_promo_instances | change_in_promo_instances |\\\\n| --- | --- | --- | --- | --- |\\\\n\\\\n\\\\nThe Change in number of holidays for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'?\\\\n\\\\n| week_starting | long_weekend_flag | number_of_holidays | poya_day_flag |\\\\n| --- | --- | --- | --- |\\\\n| 2024-01-05 | 0 | 0 | 0 |\\\\n| 2024-01-12 | 0 | 1 | 0 |\\\\n| 2024-01-19 | 1 | 1 | 1 |\\\\n\\\\n\\\\nThe change in Has the number of facings of the items for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'?\\\\n\\\\n| week_starting | stg_item_category_desc_txt | weekly_average_active_items | weekly_average_item_facings |\\\\n| --- | --- | --- | --- |\\\\n| 2024-01-05 | Crackers | 15.352 | 169.509 |\\\\n| 2024-01-12 | Crackers | 15.352 | 169.509 |\\\\n| 2024-01-19 | Crackers | 15.352 | 167.218 |\\\\n\\\\n\",\"topic2\":\"Data Presentation\"},{\"description3\":\"<ol><li>Crackers\\' unit sales increased from 53,368 units on January 5 to 57,030 units on January 19, showing a positive trend.</li><li>Gross sales also showed an upward trend, increasing from 13.17 million on January 5 to 14.31 million on January 19.</li><li>The average weekly RSP decreased slightly from 217.233 on January 5 to 213.55 on January 19.</li><li>The distinct item count decreased from 23 on January 5 to 22 on January 19.</li><li>The number of holidays increased from 0 on January 5 to 1 on January 19, with a long weekend and a Poya day on January 19.</li></ol>\",\"topic3\":\"Answers to Key Questions\"},{\"description4\":\"<ol><li>The increase in unit sales and gross sales indicates a growing demand for Crackers during the analyzed period.</li><li>The slight decrease in average weekly RSP suggests competitive pricing or promotional activities.</li><li>The decrease in distinct item count might indicate a consolidation of product offerings or a focus on best-selling items.</li><li>The increase in holidays, including a long weekend and a Poya day, likely contributed to the boost in sales performance.</li><li>The stock holding days decreased, and the fill rate improved, indicating better inventory management.</li><li>The out-of-stock rate increased slightly, which could be a concern if not addressed promptly.</li></ol>\",\"topic4\":\"Key Insights & Analysis\"},{\"description5\":\"<ol><li>The overall sales performance of Crackers has improved over the analyzed period, driven by increased demand and effective inventory management.</li><li>Promotional activities and competitive pricing have likely contributed to the positive sales trend.</li><li>However, the slight increase in the out-of-stock rate needs to be monitored to prevent potential sales losses.</li><li>It is recommended to continue monitoring the impact of holidays on sales and adjust inventory and promotional strategies accordingly.</li></ol>\",\"topic5\":\"Conclusion & Recommendations\"},{\"description6\":\"<ol><li>Analyze the impact of specific promotional activities on sales performance to identify the most effective strategies.</li><li>Investigate the reasons behind the decrease in distinct item count and its impact on overall sales.</li><li>Monitor the out-of-stock rate closely and implement measures to improve stock availability.</li><li>Conduct a deeper analysis of customer preferences and buying behavior during holidays to optimize sales strategies.</li></ol>\",\"topic6\":\"Further Areas of Investigation\"}],\"topics\":[\"The increase/decrease qty, RSP, distinct item count for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'?\",\"The increase or decrease overall volume for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'?\",\"The increase or decrease Nexus qty, penetration sales, WOP, FOP for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'?\",\"The increase or decrease Nexus volume for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'? \",\"The increase or decrease non-Nexus qty, WOP for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'? \",\"The changes in the OOS rate, SHD, and the number of item-outlet active instances for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'?\",\"The change in promotion count or distribution of promotion types for the  \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'? \",\"The Change in number of holidays for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'?\",\"The change in Has the number of facings of the items for the \\'Crackers\\' category between \\'2024-01-05\\' and \\'2024-01-19\\'?\"]}\\n\\n', 'timeranges': {'start1': '2024-01-04T18:30:00.000Z', 'end1': '2024-01-18T18:30:00.000Z', 'start2': None, 'end2': None}, 'created_at': '2025-01-07T15:31:19.628173+00:00', 'type': 'report', '_rid': '178eAL4gI5IRAAAAAAAAAA==', '_self': 'dbs/178eAA==/colls/178eAL4gI5I=/docs/178eAL4gI5IRAAAAAAAAAA==/', '_etag': '\"4100cc6c-0000-1800-0000-677d48c80000\"', '_attachments': 'attachments/', '_ts': 1736263880}'''\n",
    "ReportPDFGenerator.generate_pdf(json_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
