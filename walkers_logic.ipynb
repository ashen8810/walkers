{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tour_code</th>\n",
       "      <th>tour_title</th>\n",
       "      <th>nights</th>\n",
       "      <th>days</th>\n",
       "      <th>day</th>\n",
       "      <th>location</th>\n",
       "      <th>activity</th>\n",
       "      <th>Typical visit time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4N5DKNEBC</td>\n",
       "      <td>04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>KANDY</td>\n",
       "      <td>PINNAWELA Elephant Orphanage</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4N5DKNEBC</td>\n",
       "      <td>04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>KANDY</td>\n",
       "      <td>Cultural dance show</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4N5DKNEBC</td>\n",
       "      <td>04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NUWARA ELIYA</td>\n",
       "      <td>KANDY Temple</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4N5DKNEBC</td>\n",
       "      <td>04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NUWARA ELIYA</td>\n",
       "      <td>Peradeniya Botanical Gardens</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4N5DKNEBC</td>\n",
       "      <td>04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NUWARA ELIYA</td>\n",
       "      <td>Gem Museum</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tour_code                                         tour_title  nights  days  \\\n",
       "0  4N5DKNEBC  04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...       4     5   \n",
       "1  4N5DKNEBC  04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...       4     5   \n",
       "2  4N5DKNEBC  04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...       4     5   \n",
       "3  4N5DKNEBC  04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...       4     5   \n",
       "4  4N5DKNEBC  04 Nights_05 Days_KANDY Nuwaraeliya BENTOTA CO...       4     5   \n",
       "\n",
       "   day      location                      activity Typical visit time  \n",
       "0    1         KANDY  PINNAWELA Elephant Orphanage            Morning  \n",
       "1    1         KANDY          Cultural dance show             Evening  \n",
       "2    2  NUWARA ELIYA                 KANDY Temple             Morning  \n",
       "3    2  NUWARA ELIYA  Peradeniya Botanical Gardens            Morning  \n",
       "4    2  NUWARA ELIYA                    Gem Museum            Morning  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = [\"kandy\",\"bentota\",\"nuwara eliya\"]\n",
    "duration = 4\n",
    "\n",
    "import pandas as pd\n",
    "itinerary = pd.read_csv(\"iternary 1(in).csv\", encoding='ISO-8859-1')\n",
    "itinerary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day counts & locations for the best matched tour :'04 Nights_05 Days_KANDYPINNAWELA NUWARA ELIYACOLOMBO':\n",
      "{'colombo': 2, 'kandy': 2, 'nuwara eliya': 1}\n",
      "Final List with days\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('kandy', 1), ('nuwara eliya', 2), ('bentota', 1)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def calculate_location_percentage_by_tour(itinerary_file, locations, duration):\n",
    "    itinerary = pd.read_csv(itinerary_file, encoding='ISO-8859-1')\n",
    "    itinerary['location'] = itinerary['location'].str.lower()\n",
    "    locations = [loc.lower() for loc in locations]\n",
    "    filtered_itinerary = itinerary[itinerary['days'] == duration]\n",
    "    \n",
    "    tour_location_percentages = {}\n",
    "    \n",
    "    for tour_title, tour_data in itinerary.groupby('tour_title'):\n",
    "        unique_tour_locations = tour_data['location'].unique().tolist()\n",
    "        \n",
    "        matching_locations = [loc for loc in locations if loc in unique_tour_locations]\n",
    "        if len(unique_tour_locations) > len(locations):\n",
    "          percentage = (len(matching_locations) / len(unique_tour_locations)) * 100\n",
    "        else:\n",
    "          percentage = (len(locations) / len(unique_tour_locations)) * 100\n",
    "        \n",
    "        tour_location_percentages[tour_title] = {\n",
    "            'percentage': percentage,\n",
    "            'matched_locations': matching_locations\n",
    "        }\n",
    "    \n",
    "    return tour_location_percentages\n",
    "\n",
    "def find_best_tour(results):\n",
    "    best_tour = None\n",
    "    min_difference = 100\n",
    "\n",
    "    for tour, data in results.items():\n",
    "      difference = abs(data['percentage'] - 100)\n",
    "      if difference == 0:\n",
    "        return tour\n",
    "      if difference < min_difference:\n",
    "        min_difference = difference\n",
    "        best_tour = tour\n",
    "      elif difference == min_difference and data['percentage'] > (results.get(best_tour, {})).get('percentage',0):\n",
    "        best_tour = tour\n",
    "    return best_tour\n",
    "\n",
    "def calculate_day_counts_by_location(itinerary_file, locations, tour_title):\n",
    "    itinerary = pd.read_csv(itinerary_file, encoding='ISO-8859-1')\n",
    "    \n",
    "    itinerary['location'] = itinerary['location'].str.lower()\n",
    "\n",
    "    filtered_itinerary = itinerary[itinerary['tour_title'] == tour_title]\n",
    "    \n",
    "    unique_days = filtered_itinerary.drop_duplicates(['location','day'])\n",
    "\n",
    "    location_day_count = unique_days.groupby(\"location\")[\"day\"].count()\n",
    "\n",
    "    return location_day_count.to_dict()\n",
    "\n",
    "def find_best_tour_with_days(itinerary_file, locations, duration):\n",
    "    result = calculate_location_percentage_by_tour(itinerary_file, locations, duration)\n",
    "    best_match = find_best_tour(result)\n",
    "    day_counts = calculate_day_counts_by_location(itinerary_file, locations, best_match)\n",
    "    \n",
    "    print(f\"Day counts & locations for the best matched tour :'{best_match}':\")\n",
    "    print(day_counts)\n",
    "    \n",
    "    # Initialize location days with 0\n",
    "    location_days = {loc.lower(): 0 for loc in locations}\n",
    "    \n",
    "    current_duration = 0\n",
    "    selected_locations = []\n",
    "\n",
    "    sorted_locations = sorted(day_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # First pass: allocate full days to matching locations\n",
    "    for location, days in sorted_locations:\n",
    "        if location in location_days:\n",
    "            # Allocate full days while not exceeding total duration\n",
    "            allocatable_days = min(days, duration - current_duration)\n",
    "            location_days[location] = allocatable_days\n",
    "            current_duration += allocatable_days\n",
    "            selected_locations.append((location, allocatable_days))\n",
    "            \n",
    "            # Break if we've reached the exact duration\n",
    "            if current_duration == duration:\n",
    "                break\n",
    "    \n",
    "    selected_location_names = [loc[0] for loc in selected_locations]\n",
    "    missing_locations = [loc for loc in locations if loc not in selected_location_names]\n",
    "    i=0\n",
    "    while (current_duration != duration) or len(missing_locations) != 0:\n",
    "\n",
    "      selected_cities = [city for city, _ in selected_locations]\n",
    "      missing_locations = [city for city in locations if city not in selected_cities]\n",
    "      if current_duration < duration:\n",
    "        lowest_location = min(selected_locations, key=lambda x: x[1])\n",
    "        index = selected_locations.index(lowest_location)\n",
    "        selected_locations[index] = (lowest_location[0], lowest_location[1] + 1)\n",
    "        current_duration += 1\n",
    "      elif current_duration > duration:\n",
    "        lowest_location = max(selected_locations, key=lambda x: x[1])\n",
    "        index = selected_locations.index(lowest_location)\n",
    "        selected_locations[index] = (lowest_location[0], lowest_location[1] - 1)\n",
    "        current_duration -= 1\n",
    "\n",
    "      if len(missing_locations) != 0:\n",
    "        if current_duration == duration:\n",
    "          lowest_location = max(selected_locations, key=lambda x: x[1])\n",
    "          index = selected_locations.index(lowest_location)\n",
    "          selected_locations[index] = (lowest_location[0], lowest_location[1] - 1)\n",
    "          current_duration -= 1\n",
    "\n",
    "          selected_locations.append((missing_locations[0], 1))\n",
    "          location_days[missing_locations[0]] += 1\n",
    "          current_duration += 1\n",
    "          missing_locations.pop(0)\n",
    "        else:\n",
    "          selected_locations.append((missing_locations[0], 1))\n",
    "          location_days[missing_locations[0]] += 1\n",
    "          current_duration += 1\n",
    "          missing_locations.pop(0)\n",
    "    return list(filter(lambda x: x[1] > 0, selected_locations))\n",
    "\n",
    "selected_locations = find_best_tour_with_days(\"iternary 1(in).csv\", locations, duration)\n",
    "print(\"Final List with days\")\n",
    "selected_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortest path calculation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shortest Path:\n",
      "kandy -> nuwara eliya -> bentota -> colombo\n",
      "Total Distance: 199.61 km\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import itertools\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "def geocodes(city):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"app1/1.0 (ashen@example.com)\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(f\"https://nominatim.openstreetmap.org/search?q={city}&format=json\", headers=headers)\n",
    "        \n",
    "        data = json.loads(response.content)\n",
    "        if data:\n",
    "            latitude = float(data[0][\"lat\"])\n",
    "            longitude = float(data[0][\"lon\"])\n",
    "            return latitude, longitude\n",
    "        else:\n",
    "            print(f\"No coordinates found for {city}\")\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding {city}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def calculate_distances(selected_locations):\n",
    "    coordinates = {}\n",
    "    for location, *_ in selected_locations:\n",
    "        lat, lon = geocodes(location)\n",
    "        if lat is not None and lon is not None:\n",
    "            coordinates[location] = (lat, lon)\n",
    "        else:\n",
    "            print(f\"Could not find coordinates for {location}\")\n",
    "            return None\n",
    "    \n",
    "    distances = {}\n",
    "    for i in range(len(selected_locations)):\n",
    "        for j in range(i + 1, len(selected_locations)):\n",
    "            loc1, *_ = selected_locations[i]\n",
    "            loc2, *_ = selected_locations[j]\n",
    "            distance = geodesic(coordinates[loc1], coordinates[loc2]).km\n",
    "            distances[(loc1, loc2)] = distance\n",
    "            distances[(loc2, loc1)] = distance  # Add reverse direction\n",
    "    \n",
    "    return distances, coordinates\n",
    "\n",
    "def find_shortest_path(selected_locations):\n",
    "    # Check if Colombo is in the locations\n",
    "    colombo_exists = any(loc == \"colombo\" for loc, *_ in selected_locations)\n",
    "    \n",
    "    # If Colombo is not in the list, add it\n",
    "    if not colombo_exists:\n",
    "        selected_locations.insert(0, (\"colombo\", 1))\n",
    "    \n",
    "    # Calculate distances between locations\n",
    "    distances_result = calculate_distances(selected_locations)\n",
    "    \n",
    "    if distances_result is None:\n",
    "        return None, None\n",
    "    \n",
    "    distances, coordinates = distances_result\n",
    "    \n",
    "    locations = [loc for loc, *_ in selected_locations]\n",
    "    \n",
    "    # Ensure Colombo is the first location\n",
    "    start_location = \"colombo\"\n",
    "    locations.remove(start_location)\n",
    "    \n",
    "    # Try all possible permutations of remaining locations\n",
    "    shortest_distance = float('inf')\n",
    "    shortest_path = None\n",
    "    \n",
    "    for path in itertools.permutations(locations):\n",
    "        full_path = (start_location,) + path  # Include Colombo at the start\n",
    "        \n",
    "        total_distance = 0\n",
    "        for i in range(len(full_path) - 1):\n",
    "            total_distance += distances.get((full_path[i], full_path[i + 1]), float('inf'))\n",
    "        \n",
    "        if total_distance < shortest_distance:\n",
    "            shortest_distance = total_distance\n",
    "            shortest_path = full_path\n",
    "    \n",
    "    return shortest_path, shortest_distance\n",
    "\n",
    "path, distance = find_shortest_path(selected_locations)\n",
    "\n",
    "if path and distance:\n",
    "    print(\"\\nShortest Path:\")\n",
    "    print(\" -> \".join(reversed(path)))\n",
    "    print(f\"Total Distance: {distance:.2f} km\")\n",
    "else:\n",
    "    print(\"Could not find a valid path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just extracting the activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location\n",
      "colombo         [colombo city tour & shopping , departure airp...\n",
      "kandy           [pinnawela elephant orphanage, cultural dance ...\n",
      "nuwara eliya    [kandy temple , peradeniya botanical gardens, ...\n",
      "Name: activity, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colombo': ['colombo city tour & shopping ',\n",
       "  'departure airport drop',\n",
       "  'lotus tower'],\n",
       " 'kandy': ['pinnawela elephant orphanage',\n",
       "  'cultural dance show ',\n",
       "  'kandy temple'],\n",
       " 'nuwara eliya': ['kandy temple ',\n",
       "  'peradeniya botanical gardens',\n",
       "  'gem museum']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itinerary['location'] = itinerary['location'].str.lower()\n",
    "itinerary['activity'] = itinerary['activity'].str.lower()  # Apply lowercase to 'activity' as well\n",
    "\n",
    "\n",
    "itinerary = itinerary.drop_duplicates(subset=['location', 'activity'])\n",
    "itinerary = itinerary.dropna(subset=['location', 'activity'])\n",
    "\n",
    "path = [p.lower() for p in path]\n",
    "\n",
    "grouped_activities = itinerary.groupby(\"location\")[\"activity\"].apply(list)\n",
    "grouped_activities = grouped_activities[grouped_activities.index.isin(path)]\n",
    "print(grouped_activities)\n",
    "\n",
    "# Create a dictionary with at most 3 activities per location\n",
    "location_dict = {location: activities[:3] for location, activities in grouped_activities.items()}\n",
    "\n",
    "location_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colombo', 'bentota', 'nuwara eliya', 'kandy']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting reportlab\n",
      "  Downloading reportlab-4.2.5-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting markdown\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\ashenr\\appdata\\local\\anaconda3\\envs\\py311\\lib\\site-packages (from reportlab) (11.0.0)\n",
      "Collecting chardet (from reportlab)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Downloading reportlab-4.2.5-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 441.3 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 588.4 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 588.4 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.3/1.9 MB 762.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/1.9 MB 822.3 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/1.9 MB 822.3 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/1.9 MB 818.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 808.4 kB/s eta 0:00:00\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: soupsieve, markdown, chardet, reportlab, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 chardet-5.2.0 markdown-3.7 reportlab-4.2.5 soupsieve-2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install reportlab markdown beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from reportlab.lib import colors\n",
    "# from reportlab.lib.pagesizes import letter, landscape\n",
    "# from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "# from reportlab.lib.units import inch\n",
    "# from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle, KeepTogether\n",
    "# from reportlab.pdfgen import canvas\n",
    "# from bs4 import BeautifulSoup\n",
    "# import markdown\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "# import os\n",
    "\n",
    "# class PDFWithHeaderFooter(SimpleDocTemplate):\n",
    "#     def __init__(self, filename, logo_path=None, **kwargs):\n",
    "#         SimpleDocTemplate.__init__(self, filename, **kwargs)\n",
    "#         self.page_count = 0\n",
    "#         self.logo_path = logo_path\n",
    "        \n",
    "#     def beforePage(self):\n",
    "#         self.page_count += 1\n",
    "#         self.canv.saveState()\n",
    "        \n",
    "#         # Only draw logo if path exists and is valid\n",
    "#         if self.logo_path and os.path.exists(self.logo_path):\n",
    "#             self.canv.drawImage(self.logo_path, 40, letter[1] - 50, width=1*inch, height=0.5*inch)\n",
    "        \n",
    "#         # Header setup\n",
    "#         self.canv.setFillColor(colors.HexColor('#2C3E50'))\n",
    "#         self.canv.setFont(\"Helvetica\", 14)\n",
    "#         self.canv.drawString(letter[0] - 200, letter[1] - 30, \n",
    "#                            f\"Generated: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "#         self.canv.setStrokeColor(colors.HexColor('#BDC3C7'))\n",
    "#         self.canv.line(40, letter[1] - 60, letter[0], letter[1] - 60)\n",
    "        \n",
    "#         # Footer setup\n",
    "#         self.canv.setFont(\"Helvetica\", 14)\n",
    "#         self.canv.drawString(letter[0]/2 - 20, 30, f\"Page {self.page_count}\")\n",
    "#         self.canv.drawString(40, 30, \"Confidential\")\n",
    "#         self.canv.line(0, 50, letter[0]+100, 50)\n",
    "#         self.canv.restoreState()\n",
    "\n",
    "# def wrap_header(header, max_length=1):\n",
    "#     \"\"\"Wrap long headers into multiple lines\"\"\"\n",
    "#     if not header:\n",
    "#         return \"\"\n",
    "#     words = str(header).split()\n",
    "#     lines = []\n",
    "#     current_line = []\n",
    "    \n",
    "#     for word in words:\n",
    "#         if len(' '.join(current_line + [word])) <= max_length:\n",
    "#             current_line.append(word)\n",
    "#         else:\n",
    "#             if current_line:\n",
    "#                 lines.append(' '.join(current_line))\n",
    "#             current_line = [word]\n",
    "    \n",
    "#     if current_line:\n",
    "#         lines.append(' '.join(current_line))\n",
    "    \n",
    "#     return '\\n'.join(lines)\n",
    "\n",
    "# def process_markdown_tables(markdown_text):\n",
    "#     try:\n",
    "#         html = markdown.markdown(markdown_text, extensions=['tables'])\n",
    "#         soup = BeautifulSoup(html, 'html.parser')\n",
    "#         tables = soup.find_all('table')\n",
    "        \n",
    "#         if not tables:\n",
    "#             return None\n",
    "            \n",
    "#         all_table_data = []\n",
    "#         for table in tables:\n",
    "#             data = []\n",
    "#             headers = [wrap_header(th.get_text().strip()) for th in table.find_all('th')]\n",
    "#             if not headers:  # Skip tables without headers\n",
    "#                 continue\n",
    "                \n",
    "#             data.append(headers)\n",
    "            \n",
    "#             for row in table.find_all('tr')[1:]:\n",
    "#                 row_data = [td.get_text().strip() for td in row.find_all('td')]\n",
    "#                 if len(row_data) == len(headers):  # Only add rows that match header count\n",
    "#                     data.append(row_data)\n",
    "                \n",
    "#             if len(data) > 1:  # Only add tables with data rows\n",
    "#                 all_table_data.append(data)\n",
    "            \n",
    "#         return all_table_data\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing markdown tables: {str(e)}\")\n",
    "#         return None\n",
    "\n",
    "# def create_pdf_report(content_json, output_file, logo_path=None):\n",
    "#     try:\n",
    "#         # Validate input\n",
    "#         if not isinstance(content_json, dict) or \"Report\" not in content_json:\n",
    "#             raise ValueError(\"Invalid content_json format\")\n",
    "            \n",
    "#         doc = PDFWithHeaderFooter(\n",
    "#             output_file,\n",
    "#             logo_path=logo_path,\n",
    "#             pagesize=landscape(letter),\n",
    "#             topMargin=1.3*inch,\n",
    "#             bottomMargin=1*inch,\n",
    "#             leftMargin=0.5*inch,\n",
    "#             rightMargin=0.5*inch\n",
    "#         )\n",
    "        \n",
    "#         styles = getSampleStyleSheet()\n",
    "#         title_style = ParagraphStyle(\n",
    "#             'CustomTitle',\n",
    "#             parent=styles['Heading1'],\n",
    "#             fontSize=18,\n",
    "#             spaceAfter=20,\n",
    "#             textColor=colors.HexColor('#2C3E50')\n",
    "#         )\n",
    "        \n",
    "#         body_style = ParagraphStyle(\n",
    "#             'CustomBody',\n",
    "#             parent=styles['Normal'],\n",
    "#             fontSize=14,\n",
    "#             spaceAfter=12,\n",
    "#             leading=14\n",
    "#         )\n",
    "        \n",
    "#         elements = []\n",
    "#         elements.append(Paragraph(\"Cracker Products Sales Analysis Report\", title_style))\n",
    "#         elements.append(Paragraph(\"January 2024\", styles['Heading2']))\n",
    "#         elements.append(Spacer(1, 20))\n",
    "        \n",
    "#         for section in content_json[\"Report\"]:\n",
    "#             section_elements = []\n",
    "#             for topic_key, topic_value in section.items():\n",
    "#                 if not isinstance(topic_value, str):\n",
    "#                     continue\n",
    "                    \n",
    "#                 if topic_key.startswith(\"topic\"):\n",
    "#                     section_elements.append(Paragraph(topic_value, title_style))\n",
    "#                 elif topic_key.startswith(\"description\"):\n",
    "#                     if \"topic2\" in section:  # Handle markdown tables\n",
    "#                         tables_data = process_markdown_tables(topic_value)\n",
    "#                         if tables_data:\n",
    "#                             for table_data in tables_data:\n",
    "#                                 available_width = doc.width\n",
    "#                                 col_count = len(table_data[0])\n",
    "#                                 col_widths = [available_width/col_count] * col_count\n",
    "                                \n",
    "#                                 table = Table(table_data, repeatRows=1, colWidths=col_widths)\n",
    "#                                 table.setStyle(TableStyle([\n",
    "#                                     ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2C3E50')),\n",
    "#                                     ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "#                                     ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "#                                     ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "#                                     ('FONTSIZE', (0, 0), (-1, 0), 11),\n",
    "#                                     ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "#                                     ('BACKGROUND', (0, 1), (-1, -1), colors.Color(0.95, 0.95, 0.95)),\n",
    "#                                     ('TEXTCOLOR', (0, 1), (-1, -1), colors.HexColor('#2C3E50')),\n",
    "#                                     ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n",
    "#                                     ('FONTSIZE', (0, 1), (-1, -1), 10),\n",
    "#                                     ('GRID', (0, 0), (-1, -1), 1, colors.Color(0.8, 0.8, 0.8)),\n",
    "#                                     ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "#                                     ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "#                                     ('PADDING', (0, 0), (-1, -1), 6),\n",
    "#                                 ]))\n",
    "#                                 section_elements.append(table)\n",
    "#                                 section_elements.append(Spacer(1, 20))\n",
    "#                     else:\n",
    "#                         try:\n",
    "#                             soup = BeautifulSoup(topic_value, 'html.parser')\n",
    "#                             for element in soup.children:\n",
    "#                                 if element.name == 'p':\n",
    "#                                     section_elements.append(Paragraph(str(element.decode_contents()), body_style))\n",
    "#                                 elif element.name == 'ul':\n",
    "#                                     for li in element.find_all('li'):\n",
    "#                                         section_elements.append(Paragraph(\"• \" + li.decode_contents(), body_style))\n",
    "#                         except Exception as e:\n",
    "#                             print(f\"Error processing HTML content: {str(e)}\")\n",
    "#                             section_elements.append(Paragraph(topic_value, body_style))\n",
    "                    \n",
    "#                     section_elements.append(Spacer(1, 10))\n",
    "            \n",
    "#             elements.append(KeepTogether(section_elements))\n",
    "        \n",
    "#         doc.build(elements)\n",
    "#         return True\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error creating PDF report: {str(e)}\")\n",
    "#         return False\n",
    "# # Use with your JSON content including markdown tables\n",
    "# # Example usage\n",
    "# report_content ={\n",
    "#     \"Report\": [\n",
    "#         {\n",
    "#             \"topic1\": \"Introduction\",\n",
    "#             \"description1\": \"<p>This report provides a comprehensive analysis of the sales performance of various cracker products for the month of January 2024. The analysis includes key metrics such as total gross sales, average weekly penetration, weekly retail selling price (RSP), out-of-stock (OOS) rates, fill rates, and promotional activities. The goal is to identify top-performing and underperforming products and derive actionable insights.</p>\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"topic2\": \"Data\",\n",
    "#             \"description1\": \"\"\"\n",
    "# The increase/decrease qty, RSP, distinct item count for the 'Ambient Liquid Milk' category between '2024-05-03' and '2024-05-17'?\n",
    "\n",
    "# | week_starting | stg_item_category_desc_txt | total_weekly_gross_sales | total_weekly_unit_sales | average_weekly_rsp | weekly_distinct_item_count | pct_change_gross_sales | pct_change_unit_sales | pct_change_average_rsp | change_in_distinct_item_count |\n",
    "# | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "# | 2024-05-03 | Ambient Liquid Milk | 5.660513E7 | 129562.0 | 644.638 | 36 | NULL | NULL | NULL | NULL |\n",
    "# | 2024-05-10 | Ambient Liquid Milk | 5.7065741E7 | 132682.0 | 644.814 | 36 | 0.008 | 0.024 | 0.0 | 0 |\n",
    "# | 2024-05-17 | Ambient Liquid Milk | 5.0448661E7 | 118116.0 | 660.699 | 37 | -0.116 | -0.11 | 0.025 | 1 |\n",
    "\n",
    "\n",
    "# The increase or decrease overall volume for the 'Ambient Liquid Milk' category between '2024-05-03' and '2024-05-17'?\n",
    "\n",
    "# | week_starting | unit_of_measure | total_weekly_volume | percentage_change |\n",
    "# | --- | --- | --- | --- |\n",
    "# | 2024-05-03 | L | 100502.44 | NULL |\n",
    "# | 2024-05-10 | L | 101524.7 | 1.02 |\n",
    "# | 2024-05-17 | L | 89952.56 | -11.4 |\n",
    "# \"\"\"\n",
    "#         },\n",
    "\n",
    "#         {\n",
    "#             \"topic3\": \"Answers to Key Questions\",\n",
    "#             \"description3\": \"<p>The analysis of the sales data for January 2024 reveals the following key insights:</p><ul><li><strong>Top Performing Products:</strong> The top-performing product is the 'MUNCHEE SUPER CREAM CRACKER 490G' with the highest total gross sales of 3,688,320.0 on the week starting 2024-01-19.</li><li><strong>Underperforming Products:</strong> The 'MALIBAN CRM CRACKER POCKET PACK 85G' consistently shows the lowest sales figures, with a total gross sales of 90.0 across multiple weeks.</li><li><strong>Out-of-Stock Rates:</strong> The 'MALIBAN CRACKERS THINS 95G' has the highest monthly OOS rate of 0.873 on the week starting 2024-01-05, indicating frequent stockouts.</li><li><strong>Fill Rates:</strong> The 'MUNCHEE SUPER CREAM CRACKER 490G' achieved a perfect fill rate of 1.0 on the week starting 2024-01-19, ensuring product availability.</li></ul>\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"topic4\": \"Key Insights & Analysis\",\n",
    "#             \"description4\": \"<p>Based on the data, several key insights can be drawn:</p><ul><li><strong>Sales Performance:</strong> The 'MUNCHEE SUPER CREAM CRACKER 490G' consistently performs well, indicating strong market demand and effective distribution strategies.</li><li><strong>Stock Management:</strong> High OOS rates for certain products like 'MALIBAN CRACKERS THINS 95G' suggest issues in inventory management that need to be addressed to prevent lost sales opportunities.</li><li><strong>Product Availability:</strong> Products with high fill rates, such as 'MUNCHEE SUPER CREAM CRACKER 490G', demonstrate efficient supply chain operations, ensuring customer satisfaction.</li><li><strong>Promotional Activities:</strong> The absence of promotional activities across all products suggests potential areas for growth through targeted marketing campaigns.</li></ul>\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"topic5\": \"Conclusion & Recommendations\",\n",
    "#             \"description5\": \"<p>In conclusion, the analysis highlights the importance of effective stock management and the potential benefits of promotional activities. The 'MUNCHEE SUPER CREAM CRACKER 490G' serves as a benchmark for successful product performance, while underperforming products like 'MALIBAN CRM CRACKER POCKET PACK 85G' require strategic interventions to boost sales. Recommendations include:</p><ul><li>Implementing targeted promotional campaigns to increase product visibility and sales.</li><li>Improving inventory management practices to reduce OOS rates and enhance product availability.</li><li>Conducting further analysis to identify factors contributing to the success of top-performing products and replicating these strategies across other product lines.</li></ul>\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"topic6\": \"Further Areas of Investigation\",\n",
    "#             \"description6\": \"<p>To validate the conclusions and recommendations, further areas of investigation include:</p><ul><li>Analyzing customer feedback and preferences to understand the factors driving product performance.</li><li>Conducting competitor analysis to identify market trends and opportunities for differentiation.</li><li>Evaluating the impact of promotional activities on sales performance through controlled experiments.</li><li>Assessing the effectiveness of supply chain operations and identifying areas for improvement to enhance product availability and reduce OOS rates.</li></ul>\"\n",
    "#         }\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# create_pdf_report(report_content, 'sales_analysis_report.pdf',logo_path=\"octave.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch, mm\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, KeepTogether\n",
    "from reportlab.pdfgen import canvas\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class PDFWithHeaderFooter(SimpleDocTemplate):\n",
    "    def __init__(self, filename, **kwargs):\n",
    "        SimpleDocTemplate.__init__(self, filename, **kwargs)\n",
    "        self.page_count = 0\n",
    "        \n",
    "    def beforePage(self):\n",
    "        self.page_count += 1\n",
    "        self.canv.saveState()\n",
    "        \n",
    "        # Header with logo\n",
    "        logo_path = \"octave.png\"\n",
    "        try:\n",
    "            self.canv.drawImage(logo_path, 20*mm, A4[1] - 25*mm, width=25*mm, height=12.5*mm)\n",
    "        except:\n",
    "            self.canv.setFont(\"Helvetica-Bold\", 20)\n",
    "            self.canv.drawString(20*mm, A4[1] - 25*mm, \"COMPANY\")\n",
    "        \n",
    "        # Header text\n",
    "        self.canv.setFont(\"Helvetica\", 9)\n",
    "        self.canv.drawString(A4[0] - 80*mm, A4[1] - 15*mm,\n",
    "                          f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "        \n",
    "        self.canv.line(20*mm, A4[1] - 30*mm, A4[0] - 20*mm, A4[1] - 30*mm)\n",
    "        \n",
    "        # Footer\n",
    "        self.canv.setFont(\"Helvetica\", 9)\n",
    "        footer_text = f\"Page {self.page_count}\"\n",
    "        self.canv.drawString(A4[0]/2 - 10*mm, 15*mm, footer_text)\n",
    "        self.canv.drawString(20*mm, 15*mm, \"Confidential\")\n",
    "        \n",
    "        self.canv.line(20*mm, 25*mm, A4[0] - 20*mm, 25*mm)\n",
    "        self.canv.restoreState()\n",
    "\n",
    "def process_markdown_tables(markdown_text):\n",
    "    \"\"\"Process markdown text and extract tables\"\"\"\n",
    "    html = markdown.markdown(markdown_text, extensions=['tables'])\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    tables = []\n",
    "    for table in soup.find_all('table'):\n",
    "        data = []\n",
    "        headers = [Paragraph(th.get_text().strip(), ParagraphStyle('Header', wordWrap='CJK')) \n",
    "                  for th in table.find_all('th')]\n",
    "        if headers:\n",
    "            data.append(headers)\n",
    "        \n",
    "        for row in table.find_all('tr'):\n",
    "            if not row.find_all('th'):  # Skip header row\n",
    "                row_data = [Paragraph(td.get_text().strip(), ParagraphStyle('Cell', wordWrap='CJK')) \n",
    "                           for td in row.find_all('td')]\n",
    "                if row_data:\n",
    "                    data.append(row_data)\n",
    "        \n",
    "        tables.append(data)\n",
    "        table.decompose()\n",
    "    \n",
    "    remaining_text = soup.get_text().strip()\n",
    "    return remaining_text, tables\n",
    "\n",
    "def process_html_content(html_content):\n",
    "    \"\"\"Process HTML content and convert to reportlab paragraphs\"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    elements = []\n",
    "    styles = getSampleStyleSheet()\n",
    "    \n",
    "    for element in soup.find_all(['p', 'ul']):\n",
    "        if element.name == 'p':\n",
    "            elements.append(Paragraph(str(element), styles['Normal']))\n",
    "        elif element.name == 'ul':\n",
    "            for li in element.find_all('li'):\n",
    "                bullet_text = f\"• {li.get_text()}\"\n",
    "                elements.append(Paragraph(bullet_text, styles['Normal']))\n",
    "    \n",
    "    return elements\n",
    "\n",
    "def create_table_style():\n",
    "    \"\"\"Create consistent table style\"\"\"\n",
    "    return TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, 0), 12),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
    "        ('TEXTCOLOR', (0, 1), (-1, -1), colors.black),\n",
    "        ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n",
    "        ('FONTSIZE', (0, 1), (-1, -1), 10),\n",
    "        ('GRID', (0, 0), (-1, -1), 1, colors.black),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('PADDING', (0, 0), (-1, -1), 6),\n",
    "        ('WORDWRAP', (0, 0), (-1, -1), True),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 3*mm),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 3*mm),\n",
    "    ])\n",
    "\n",
    "def generate_sales_report_pdf(json_data, output_pdf):\n",
    "    # Calculate usable width (A4 width minus margins)\n",
    "    margin = 20*mm  # 20mm margins on each side\n",
    "    usable_width = A4[0] - 2*margin\n",
    "    \n",
    "    doc = PDFWithHeaderFooter(\n",
    "        output_pdf,\n",
    "        pagesize=A4,\n",
    "        topMargin=35*mm,\n",
    "        bottomMargin=30*mm,\n",
    "        leftMargin=margin,\n",
    "        rightMargin=margin\n",
    "    )\n",
    "    \n",
    "    styles = getSampleStyleSheet()\n",
    "    elements = []\n",
    "    \n",
    "    # Title\n",
    "    title_style = ParagraphStyle(\n",
    "        'CustomTitle',\n",
    "        parent=styles['Title'],\n",
    "        fontSize=24,\n",
    "        spaceAfter=30\n",
    "    )\n",
    "    elements.append(Paragraph(\"Sales Performance Analysis Report\", title_style))\n",
    "    \n",
    "    # Topic style\n",
    "    topic_style = ParagraphStyle(\n",
    "        'TopicStyle',\n",
    "        parent=styles['Heading1'],\n",
    "        fontSize=18,\n",
    "        spaceAfter=20,\n",
    "        spaceBefore=30\n",
    "    )\n",
    "    \n",
    "    for i, section in enumerate(json_data, 1):\n",
    "        # Get the topic and description keys\n",
    "        topic_key = next(key for key in section.keys() if key.startswith('topic'))\n",
    "        desc_key = next(key for key in section.keys() if key.startswith('description'))\n",
    "        \n",
    "        # Create section elements\n",
    "        section_elements = []\n",
    "        \n",
    "        # Add topic heading\n",
    "        topic_text = section[topic_key]\n",
    "        section_elements.append(Paragraph(topic_text, topic_style))\n",
    "        \n",
    "        description = section[desc_key]\n",
    "        \n",
    "        # Check if content is markdown (contains table markers)\n",
    "        if '|' in description and '---' in description:\n",
    "            # Process markdown content\n",
    "            text, tables = process_markdown_tables(description)\n",
    "            if text:\n",
    "                section_elements.append(Paragraph(text, styles['Normal']))\n",
    "            \n",
    "            # Add tables\n",
    "            for table_data in tables:\n",
    "                if table_data:\n",
    "                    # Calculate column widths to fit within usable width\n",
    "                    num_cols = len(table_data[0])\n",
    "                    col_width = usable_width / num_cols\n",
    "                    col_widths = [col_width] * num_cols\n",
    "                    \n",
    "                    table = Table(table_data, colWidths=col_widths, repeatRows=1)\n",
    "                    table.setStyle(create_table_style())\n",
    "                    # Always wrap tables in KeepTogether\n",
    "                    section_elements.append(KeepTogether(table))\n",
    "                    section_elements.append(Spacer(1, 20))\n",
    "        else:\n",
    "            # Process HTML content\n",
    "            html_elements = process_html_content(description)\n",
    "            section_elements.extend(html_elements)\n",
    "        \n",
    "        section_elements.append(Spacer(1, 20))\n",
    "        \n",
    "        # If it's the second section, don't wrap in KeepTogether\n",
    "        if i == 2:\n",
    "            elements.extend(section_elements)\n",
    "        else:\n",
    "            # Wrap all other sections in KeepTogether\n",
    "            elements.append(KeepTogether(section_elements))\n",
    "    \n",
    "    doc.build(elements)\n",
    "if __name__ == \"__main__\":\n",
    "    json_data = [\n",
    "        {\n",
    "            \"topic1\": \"Introduction\",\n",
    "            \"description1\": \"<p>This report provides a comprehensive analysis of the sales performance of various cracker products for the month of January 2024. The analysis includes key metrics such as total gross sales, average weekly penetration, weekly retail selling price (RSP), out-of-stock (OOS) rates, fill rates, and promotional activities. The goal is to identify top-performing and underperforming products and derive actionable insights.</p>\"\n",
    "        },\n",
    "         {\n",
    "            \"topic3\": \"Answers to Key Questions\",\n",
    "            \"description3\": \"<p>The analysis of the sales data for January 2024 reveals the following key insights:</p><ul><li><strong>Top Performing Products:</strong> The top-performing product is the 'MUNCHEE SUPER CREAM CRACKER 490G' with the highest total gross sales of 3,688,320.0 on the week starting 2024-01-19.</li><li><strong>Underperforming Products:</strong> The 'MALIBAN CRM CRACKER POCKET PACK 85G' consistently shows the lowest sales figures, with a total gross sales of 90.0 across multiple weeks.</li><li><strong>Out-of-Stock Rates:</strong> The 'MALIBAN CRACKERS THINS 95G' has the highest monthly OOS rate of 0.873 on the week starting 2024-01-05, indicating frequent stockouts.</li><li><strong>Fill Rates:</strong> The 'MUNCHEE SUPER CREAM CRACKER 490G' achieved a perfect fill rate of 1.0 on the week starting 2024-01-19, ensuring product availability.</li></ul>\"\n",
    "        },\n",
    "        {\n",
    "            \"topic2\": \"Data Representation\",\n",
    "            \"description1\": \"\"\" \n",
    "            The increase/decrease qty, RSP, distinct item count for the 'Ambient Liquid Milk' category between '2024-05-03' and '2024-05-17'?\n",
    "\n",
    "| week_starting | stg_item_category_desc_txt | total_weekly_gross_sales | total_weekly_unit_sales | average_weekly_rsp | weekly_distinct_item_count | pct_change_gross_sales | pct_change_unit_sales | pct_change_average_rsp | change_in_distinct_item_count |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 2024-05-03 | Ambient Liquid Milk | 5.660513E7 | 129562.0 | 644.638 | 36 | NULL | NULL | NULL | NULL |\n",
    "| 2024-05-10 | Ambient Liquid Milk | 5.7065741E7 | 132682.0 | 644.814 | 36 | 0.008 | 0.024 | 0.0 | 0 |\n",
    "| 2024-05-17 | Ambient Liquid Milk | 5.0448661E7 | 118116.0 | 660.699 | 37 | -0.116 | -0.11 | 0.025 | 1 |\n",
    "\n",
    "| week_starting | stg_item_category_desc_txt | total_weekly_gross_sales | total_weekly_unit_sales | average_weekly_rsp | weekly_distinct_item_count | pct_change_gross_sales | pct_change_unit_sales | pct_change_average_rsp | change_in_distinct_item_count |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 2024-05-03 | Ambient Liquid Milk | 5.660513E7 | 129562.0 | 644.638 | 36 | NULL | NULL | NULL | NULL |\n",
    "| 2024-05-10 | Ambient Liquid Milk | 5.7065741E7 | 132682.0 | 644.814 | 36 | 0.008 | 0.024 | 0.0 | 0 |\n",
    "| 2024-05-17 | Ambient Liquid Milk | 5.0448661E7 | 118116.0 | 660.699 | 37 | -0.116 | -0.11 | 0.025 | 1 |\n",
    "\n",
    "| week_starting | stg_item_category_desc_txt | total_weekly_gross_sales | total_weekly_unit_sales | average_weekly_rsp | weekly_distinct_item_count | pct_change_gross_sales | pct_change_unit_sales | pct_change_average_rsp | change_in_distinct_item_count |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 2024-05-03 | Ambient Liquid Milk | 5.660513E7 | 129562.0 | 644.638 | 36 | NULL | NULL | NULL | NULL |\n",
    "| 2024-05-10 | Ambient Liquid Milk | 5.7065741E7 | 132682.0 | 644.814 | 36 | 0.008 | 0.024 | 0.0 | 0 |\n",
    "| 2024-05-17 | Ambient Liquid Milk | 5.0448661E7 | 118116.0 | 660.699 | 37 | -0.116 | -0.11 | 0.025 | 1 |\n",
    "\n",
    "The increase or decrease overall volume for the 'Ambient Liquid Milk' category between '2024-05-03' and '2024-05-17'?\n",
    "\n",
    "| week_starting | unit_of_measure | total_weekly_volume | percentage_change |\n",
    "| --- | --- | --- | --- |\n",
    "| 2024-05-03 | L | 100502.44 | NULL |\n",
    "| 2024-05-10 | L | 101524.7 | 1.02 |\n",
    "| 2024-05-17 | L | 89952.56 | -11.4 |\n",
    "\n",
    "The increase/decrease qty, RSP, distinct item count for the 'Ambient Liquid Milk' category between '2024-05-03' and '2024-05-17'?\n",
    "\n",
    "| week_starting | stg_item_category_desc_txt | total_weekly_gross_sales | total_weekly_unit_sales | average_weekly_rsp | weekly_distinct_item_count | pct_change_gross_sales | pct_change_unit_sales | pct_change_average_rsp | change_in_distinct_item_count |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 2024-05-03 | Ambient Liquid Milk | 5.660513E7 | 129562.0 | 644.638 | 36 | NULL | NULL | NULL | NULL |\n",
    "| 2024-05-10 | Ambient Liquid Milk | 5.7065741E7 | 132682.0 | 644.814 | 36 | 0.008 | 0.024 | 0.0 | 0 |\n",
    "| 2024-05-17 | Ambient Liquid Milk | 5.0448661E7 | 118116.0 | 660.699 | 37 | -0.116 | -0.11 | 0.025 | 1 |\n",
    "\n",
    "\n",
    "The increase or decrease overall volume for the 'Ambient Liquid Milk' category between '2024-05-03' and '2024-05-17'?\n",
    "\n",
    "| week_starting | unit_of_measure | total_weekly_volume | percentage_change |\n",
    "| --- | --- | --- | --- |\n",
    "| 2024-05-03 | L | 100502.44 | NULL |\n",
    "| 2024-05-10 | L | 101524.7 | 1.02 |\n",
    "| 2024-05-17 | L | 89952.56 | -11.4 |\n",
    "\"\"\"\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"topic3\": \"Answers to Key Questions\",\n",
    "            \"description3\": \"<p>The analysis of the sales data for January 2024 reveals the following key insights:</p><ul><li><strong>Top Performing Products:</strong> The top-performing product is the 'MUNCHEE SUPER CREAM CRACKER 490G' with the highest total gross sales of 3,688,320.0 on the week starting 2024-01-19.</li><li><strong>Underperforming Products:</strong> The 'MALIBAN CRM CRACKER POCKET PACK 85G' consistently shows the lowest sales figures, with a total gross sales of 90.0 across multiple weeks.</li><li><strong>Out-of-Stock Rates:</strong> The 'MALIBAN CRACKERS THINS 95G' has the highest monthly OOS rate of 0.873 on the week starting 2024-01-05, indicating frequent stockouts.</li><li><strong>Fill Rates:</strong> The 'MUNCHEE SUPER CREAM CRACKER 490G' achieved a perfect fill rate of 1.0 on the week starting 2024-01-19, ensuring product availability.</li></ul>\"\n",
    "        },\n",
    "        {\n",
    "            \"topic4\": \"Key Insights & Analysis\",\n",
    "            \"description4\": \"<p>Based on the data, several key insights can be drawn:</p><ul><li><strong>Sales Performance:</strong> The 'MUNCHEE SUPER CREAM CRACKER 490G' consistently performs well, indicating strong market demand and effective distribution strategies.</li><li><strong>Stock Management:</strong> High OOS rates for certain products like 'MALIBAN CRACKERS THINS 95G' suggest issues in inventory management that need to be addressed to prevent lost sales opportunities.</li><li><strong>Product Availability:</strong> Products with high fill rates, such as 'MUNCHEE SUPER CREAM CRACKER 490G', demonstrate efficient supply chain operations, ensuring customer satisfaction.</li><li><strong>Promotional Activities:</strong> The absence of promotional activities across all products suggests potential areas for growth through targeted marketing campaigns.</li></ul>\"\n",
    "        },\n",
    "        {\n",
    "            \"topic5\": \"Conclusion & Recommendations\",\n",
    "            \"description5\": \"<p>In conclusion, the analysis highlights the importance of effective stock management and the potential benefits of promotional activities. The 'MUNCHEE SUPER CREAM CRACKER 490G' serves as a benchmark for successful product performance, while underperforming products like 'MALIBAN CRM CRACKER POCKET PACK 85G' require strategic interventions to boost sales. Recommendations include:</p><ul><li>Implementing targeted promotional campaigns to increase product visibility and sales.</li><li>Improving inventory management practices to reduce OOS rates and enhance product availability.</li><li>Conducting further analysis to identify factors contributing to the success of top-performing products and replicating these strategies across other product lines.</li></ul>\"\n",
    "        },\n",
    "        {\n",
    "            \"topic6\": \"Further Areas of Investigation\",\n",
    "            \"description6\": \"<p>To validate the conclusions and recommendations, further areas of investigation include:</p><ul><li>Analyzing customer feedback and preferences to understand the factors driving product performance.</li><li>Conducting competitor analysis to identify market trends and opportunities for differentiation.</li><li>Evaluating the impact of promotional activities on sales performance through controlled experiments.</li><li>Assessing the effectiveness of supply chain operations and identifying areas for improvement to enhance product availability and reduce OOS rates.</li></ul>\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "    # json_data = json.load(json_data)\n",
    "    generate_sales_report_pdf(json_data, \"sales_report.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
